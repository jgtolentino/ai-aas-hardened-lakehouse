# ğŸ”ï¸ AI-AAS Hardened Lakehouse

A production-grade monorepo for pseudonymous customer intelligence and transaction clustering analytics. Built with security-hardened infrastructure, geographic visualization capabilities, and enterprise-grade CI/CD pipelines.

## ğŸš€ Features

### Core Platform
- **Production-Grade Monorepo**: pnpm workspaces + Turborepo for build orchestration
- **Complete ETL/ELT Pipeline**: Bronze â†’ Silver â†’ Gold â†’ Platinum architecture
- **Geographic Visualization**: PostGIS-powered choropleth maps with Mapbox integration  
- **Security Hardened**: RLS, Gatekeeper policies, network isolation
- **Cloud Native**: Kubernetes-ready with Helm charts, Docker images published to GHCR
- **API-First**: Automated deployment via Bruno API collections
- **Performance Optimized**: GIST indexes, materialized views, <1.5s query SLA
- **CI/CD Pipeline**: GitHub Actions with required checks, branch protection, and automated testing

### Microservices Architecture
- **API Service**: FastAPI (Python) - RESTful API endpoints
- **Worker Service**: Fastify (Node.js) - Background job processing
- **Brand Model Service**: FastAPI (Python) - RapidFuzz-powered brand detection
- **Edge Functions**: Supabase Edge Functions for real-time processing
- **Database**: PostgreSQL with pgvector extension for embeddings

### Dataset Publisher & Management (New! ğŸ‰)
- **Usage Analytics Dashboard**: Comprehensive tracking of dataset downloads, API calls, and user engagement
- **Dataset Versioning**: Semantic versioning with rollback capabilities and lineage tracking
- **Cross-Region Replication**: Global dataset availability with cost optimization
- **Subscription Notifications**: Multi-channel alerts (email, webhook, in-app, SMS, Slack)
- **Parquet Export Support**: High-performance columnar format with schema validation
- **Edge Device Integration**: Secure token-based uploads from Raspberry Pi devices
- **Automated Testing**: Comprehensive test suites with CI/CD integration

### Enterprise Features
- **Multi-Tenant Support**: Complete data isolation with RLS policies
- **Monitoring & Alerts**: Real-time dataset freshness and quality monitoring
- **Cost Management**: Replication cost estimation and optimization
- **API Documentation**: Auto-generated docs with OpenAPI integration

## ğŸ“Š Complete Data Stack

### Core Components
- **Storage**: MinIO (S3-compatible object storage)
- **Table Format**: Apache Iceberg with Nessie catalog
- **Query Engine**: Trino (distributed SQL)
- **Transformation**: dbt (data build tool)
- **Orchestration**: Apache Airflow
- **Visualization**: Apache Superset with Deck.gl
- **Database**: PostgreSQL with PostGIS
- **API Layer**: Supabase (PostgREST)

### Supporting Infrastructure
- **Container Orchestration**: Kubernetes
- **Security**: OPA Gatekeeper, Network Policies
- **Monitoring**: Prometheus + Grafana
- **CI/CD**: GitHub Actions
- **API Testing**: Bruno
- **Model Context Protocol**: Claude MCP integration

## ğŸ—‚ï¸ Production Monorepo Structure

```
ai-aas-hardened-lakehouse/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ ci.yml                      # DB/Build/Test workflow
â”‚   â”‚   â”œâ”€â”€ dataset-publisher-tests.yml # Package testing
â”‚   â”‚   â”œâ”€â”€ edge-functions.yml          # Edge function tests
â”‚   â”‚   â”œâ”€â”€ release-images.yml          # Docker image publishing to GHCR
â”‚   â”‚   â””â”€â”€ security-scan.yml           # Security analysis
â”‚   â””â”€â”€ branch-protection.json          # Required status checks
â”‚
â”œâ”€â”€ apps/                               # Frontend applications
â”‚   â””â”€â”€ scout-dashboard/                # Retail analytics UI
â”‚
â”œâ”€â”€ db/                                 # Database layer
â”‚   â”œâ”€â”€ migrations/                     # SQL migrations (000-999)
â”‚   â”‚   â”œâ”€â”€ 000_extensions.sql          # pgcrypto, pg_trgm, vector
â”‚   â”‚   â”œâ”€â”€ 100_scouts_dims.sql         # Dimension tables
â”‚   â”‚   â”œâ”€â”€ 200_scouts_bronze.sql       # Bronze layer
â”‚   â”‚   â”œâ”€â”€ 210_scouts_silver.sql       # Silver layer
â”‚   â”‚   â””â”€â”€ 220_scouts_gold.sql         # Gold layer views
â”‚   â”œâ”€â”€ seeds/                          # Seed data
â”‚   â””â”€â”€ views/                          # Database views
â”‚
â”œâ”€â”€ dq/                                 # Data quality
â”‚   â””â”€â”€ checks/                         # DQ validation scripts
â”‚
â”œâ”€â”€ infra/                              # Infrastructure
â”‚   â””â”€â”€ docker/
â”‚       â”œâ”€â”€ compose.yml                 # Local dev environment
â”‚       â””â”€â”€ Dockerfile.base             # Base image with common deps
â”‚
â”œâ”€â”€ packages/                           # Shared packages
â”‚   â”œâ”€â”€ shared-types/                   # TypeScript types
â”‚   â””â”€â”€ common-utils/                   # Utility functions
â”‚
â”œâ”€â”€ services/                           # Microservices
â”‚   â”œâ”€â”€ api/                            # FastAPI REST service
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ worker/                         # Fastify background jobs
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ package.json
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â””â”€â”€ brand-model/                    # Brand detection service
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ main.py
â”‚
â”œâ”€â”€ scripts/                            # Operational scripts
â”‚   â”œâ”€â”€ setup-db.sh                     # Database setup
â”‚   â””â”€â”€ verify-deployment.sh            # Deployment verification
â”‚
â”œâ”€â”€ pnpm-workspace.yaml                 # pnpm workspace config
â”œâ”€â”€ turbo.json                          # Turborepo config
â”œâ”€â”€ pnpm-lock.yaml                      # Lockfile
â””â”€â”€ package.json                        # Root package.json
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ setup/
â”‚       â”œâ”€â”€ choropleth_optimization.md  # Geographic visualization guide
â”‚       â””â”€â”€ mapbox_setup.md             # Mapbox configuration
â”‚
â”œâ”€â”€ helm-overlays/
â”‚   â””â”€â”€ superset-values-prod.yaml       # Production Helm values
â”‚
â”œâ”€â”€ observability/
â”‚   â”œâ”€â”€ alerting/
â”‚   â”‚   â””â”€â”€ slo-alerts.yaml            # SLO-based alerting rules
â”‚   â””â”€â”€ grafana-dashboards/
â”‚       â””â”€â”€ scout-slos.json            # Performance dashboards
â”‚
â”œâ”€â”€ platform/
â”‚   â”œâ”€â”€ cloud-wire/                    # API-first cloud integration
â”‚   â”‚   â”œâ”€â”€ .env.example               # Environment template
â”‚   â”‚   â”œâ”€â”€ README.md                  # Cloud wire documentation
â”‚   â”‚   â”œâ”€â”€ bruno/                     # API test collection
â”‚   â”‚   â”‚   â”œâ”€â”€ bruno.json
â”‚   â”‚   â”‚   â”œâ”€â”€ environments/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ production.bru
â”‚   â”‚   â”‚   â””â”€â”€ requests/
â”‚   â”‚   â”‚       â”œâ”€â”€ 01_login.bru       # Superset authentication
â”‚   â”‚   â”‚       â”œâ”€â”€ 02_csrf.bru        # CSRF token retrieval
â”‚   â”‚   â”‚       â”œâ”€â”€ 03_create_db_conn.bru
â”‚   â”‚   â”‚       â”œâ”€â”€ 04_import_bundle.bru
â”‚   â”‚   â”‚       â”œâ”€â”€ 05_test_choropleth.bru
â”‚   â”‚   â”‚       â””â”€â”€ 06_verify_geo_data.bru
â”‚   â”‚   â”œâ”€â”€ mcp/                       # Model Context Protocol
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp.json              # MCP configuration
â”‚   â”‚   â”‚   â””â”€â”€ README.txt
â”‚   â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”‚   â””â”€â”€ run_cloud_wire.sh     # Automated deployment
â”‚   â”‚   â””â”€â”€ superset/
â”‚   â”‚       â””â”€â”€ assets/
â”‚   â”‚           â”œâ”€â”€ charts/            # Visualization definitions
â”‚   â”‚           â”œâ”€â”€ dashboards/        # Dashboard configurations
â”‚   â”‚           â”œâ”€â”€ datasets/          # Dataset mappings
â”‚   â”‚           â””â”€â”€ databases/         # Database connections
â”‚   â”‚
â”‚   â”œâ”€â”€ lakehouse/                     # Core lakehouse infrastructure
â”‚   â”‚   â”œâ”€â”€ dbt/
â”‚   â”‚   â”‚   â”œâ”€â”€ dbt-cronjob.yaml      # dbt scheduler
â”‚   â”‚   â”‚   â”œâ”€â”€ models/                # dbt transformations
â”‚   â”‚   â”‚   â””â”€â”€ profiles.yml
â”‚   â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”‚   â””â”€â”€ geo-importer.yaml     # Geographic boundary importer
â”‚   â”‚   â”œâ”€â”€ minio/
â”‚   â”‚   â”‚   â””â”€â”€ init-bucket.yaml      # S3 bucket initialization
â”‚   â”‚   â”œâ”€â”€ nessie/
â”‚   â”‚   â”‚   â””â”€â”€ values-oss.yaml       # Iceberg catalog config
â”‚   â”‚   â””â”€â”€ trino/
â”‚   â”‚       â””â”€â”€ values-oss.yaml        # Query engine config
â”‚   â”‚
â”‚   â”œâ”€â”€ scout/                         # Scout Analytics Platform
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ deploy.sh                  # Deployment script
â”‚   â”‚   â”œâ”€â”€ bruno/                     # API test collection
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_auth.bru            # Authentication tests
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_health.bru          # Health checks
â”‚   â”‚   â”‚   â”œâ”€â”€ ...                    # (03-21 test files)
â”‚   â”‚   â”‚   â”œâ”€â”€ 20_choropleth_smoke.bru
â”‚   â”‚   â”‚   â”œâ”€â”€ 21_mapbox_verify.bru
â”‚   â”‚   â”‚   â”œâ”€â”€ collection_summary.md
â”‚   â”‚   â”‚   â””â”€â”€ environments/
â”‚   â”‚   â”‚       â”œâ”€â”€ production.bru
â”‚   â”‚   â”‚       â””â”€â”€ staging.bru
â”‚   â”‚   â”œâ”€â”€ functions/                 # Edge functions  
â”‚   â”‚   â”‚   â”œâ”€â”€ embed-batch.ts         # Batch embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ genie-query.ts         # AI-powered queries
â”‚   â”‚   â”‚   â”œâ”€â”€ usage-analytics/       # Dataset usage tracking
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset-versioning/    # Version control system
â”‚   â”‚   â”‚   â”œâ”€â”€ cross-region-replication/ # Multi-region sync
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset-subscriptions/ # Notification system
â”‚   â”‚   â”‚   â”œâ”€â”€ export-parquet/        # Parquet format export
â”‚   â”‚   â”‚   â””â”€â”€ superset-jwt-proxy/    # JWT authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest-doc.ts          # Document ingestion
â”‚   â”‚   â”‚   â””â”€â”€ ingest-transaction.ts  # Transaction processing
â”‚   â”‚   â”œâ”€â”€ migrations/                # Database migrations
â”‚   â”‚   â”‚   â”œâ”€â”€ 001_scout_enums_dims.sql      # Base schema
â”‚   â”‚   â”‚   â”œâ”€â”€ 002_scout_bronze_silver.sql   # Bronze/Silver layers
â”‚   â”‚   â”‚   â”œâ”€â”€ 003_scout_gold_views.sql      # Gold layer views
â”‚   â”‚   â”‚   â”œâ”€â”€ 004_scout_platinum_features.sql # Advanced features
â”‚   â”‚   â”‚   â”œâ”€â”€ 005_scout_rls_policies.sql    # Security policies
â”‚   â”‚   â”‚   â”œâ”€â”€ 006_ingest_idempotency.sql    # Deduplication
â”‚   â”‚   â”‚   â”œâ”€â”€ 007_gold_refresh.sql          # MV refresh logic
â”‚   â”‚   â”‚   â”œâ”€â”€ 008_view_silver_last.sql      # Latest data views
â”‚   â”‚   â”‚   â”œâ”€â”€ 009_perf_indexes.sql          # Performance indexes
â”‚   â”‚   â”‚   â”œâ”€â”€ 010_geo_boundaries.sql        # PostGIS setup
â”‚   â”‚   â”‚   â”œâ”€â”€ 011_geo_normalizers.sql       # Name normalization
â”‚   â”‚   â”‚   â”œâ”€â”€ 012_geo_gold_views.sql        # Geographic views
â”‚   â”‚   â”‚   â”œâ”€â”€ 013_geo_performance_indexes.sql # Spatial indexes
â”‚   â”‚   â”‚   â”œâ”€â”€ 022_usage_analytics_schema.sql # Usage tracking
â”‚   â”‚   â”‚   â”œâ”€â”€ 023_dataset_versioning_schema.sql # Version control
â”‚   â”‚   â”‚   â”œâ”€â”€ 024_cross_region_replication_schema.sql # Multi-region
â”‚   â”‚   â”‚   â””â”€â”€ 025_dataset_subscription_schema.sql # Notifications
â”‚   â”‚   â”œâ”€â”€ quality/                   # Data quality
â”‚   â”‚   â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ expectations/
â”‚   â”‚   â”‚   â”œâ”€â”€ great_expectations.yml
â”‚   â”‚   â”‚   â””â”€â”€ sql_quality_checks.sql
â”‚   â”‚   â””â”€â”€ superset/
â”‚   â”‚       â””â”€â”€ scout_dashboard.yaml   # Dashboard config
â”‚   â”‚
â”‚   â”œâ”€â”€ security/                      # Security policies
â”‚   â”‚   â”œâ”€â”€ gatekeeper/               # Admission controllers
â”‚   â”‚   â”‚   â”œâ”€â”€ constraints/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ forbid-latest-tags.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ require-probes.yaml
â”‚   â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚   â”‚       â”œâ”€â”€ k8scontainerprobes_template.yaml
â”‚   â”‚   â”‚       â””â”€â”€ no-latest-tags_template.yaml
â”‚   â”‚   â””â”€â”€ netpol/                   # Network policies
â”‚   â”‚       â”œâ”€â”€ 01-trino-policies.yaml
â”‚   â”‚       â””â”€â”€ 02-superset-policies.yaml
â”‚   â”‚
â”‚   â””â”€â”€ superset/                     # Visualization layer
â”‚       â”œâ”€â”€ assets/
â”‚       â”‚   â”œâ”€â”€ charts/
â”‚       â”‚   â”‚   â”œâ”€â”€ citymun_choropleth.yaml    # City-level map
â”‚       â”‚   â”‚   â””â”€â”€ region_choropleth.yaml     # Regional map
â”‚       â”‚   â””â”€â”€ datasets/
â”‚       â”‚       â”œâ”€â”€ gold_citymun_choropleth.yaml
â”‚       â”‚       â””â”€â”€ gold_region_choropleth.yaml
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ mapbox_config.py      # Map configuration
â”‚       â”œâ”€â”€ docker/
â”‚       â”‚   â”œâ”€â”€ .env.example
â”‚       â”‚   â””â”€â”€ superset_config_additions.py
â”‚       â”œâ”€â”€ scripts/
â”‚       â”‚   â”œâ”€â”€ import_supabase_bundle.sh
â”‚       â”‚   â””â”€â”€ import_trino_bundle.sh
â”‚       â””â”€â”€ superset_config.py        # Main configuration
â”‚
â”œâ”€â”€ scripts/                          # Operational scripts
â”‚   â”œâ”€â”€ benchmark_choropleth.py       # Performance benchmarking
â”‚   â”œâ”€â”€ benchmark_choropleth_hard.py  # Hard performance gates
â”‚   â”œâ”€â”€ deploy_superset_with_mapbox.sh
â”‚   â”œâ”€â”€ run_bruno_tests.sh           # Test automation
â”‚   â”œâ”€â”€ test_choropleth_performance.sql
â”‚   â”œâ”€â”€ verify_choropleth_complete.sh
â”‚   â””â”€â”€ verify_geo_deployment.sh
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ ARCHITECTURE_FLOW.md              # System architecture
â”œâ”€â”€ DEPLOYMENT_CHECKLIST.md           # Deployment guide
â”œâ”€â”€ DEPLOYMENT_STATUS.md              # Current status
â”œâ”€â”€ FINAL_PROJECT_SUMMARY.md          # Project overview
â”œâ”€â”€ Makefile                          # Build automation
â”œâ”€â”€ README.md                         # This file
â”œâ”€â”€ STRUCTURE_VALIDATION.md           # Validation rules
â””â”€â”€ validate_deployment.sh            # Deployment validation
```

## ğŸ“ Complete Database Schema (DBML)

```dbml
// Scout Analytics Data Model
// Complete schema including all master data, transactional, and derived objects

Project ScoutAnalytics {
  database_type: 'PostgreSQL'
  Note: 'Hardened Lakehouse with Geographic Capabilities'
}

// ==========================================
// ENUMS & CUSTOM TYPES
// ==========================================

enum time_of_day {
  morning [note: '6 AM - 12 PM']
  afternoon [note: '12 PM - 6 PM']
  evening [note: '6 PM - 10 PM']
  night [note: '10 PM - 6 AM']
}

enum customer_type {
  new
  returning
  vip
  churned
}

enum product_category {
  beverages
  snacks
  personal_care
  household
  tobacco
  other
}

enum payment_method {
  cash
  gcash
  maya
  card
  other
}

enum campaign_type {
  promo
  seasonal
  loyalty
  flash_sale
  bundle
}

enum channel_type {
  store
  online
  wholesale
  b2b
}

enum income_class {
  '1st'
  '2nd'
  '3rd'
  '4th'
  '5th'
  '6th'
}

// ==========================================
// MASTER DATA TABLES (Dimensions)
// ==========================================

Table scout.dim_store {
  store_id TEXT [pk, note: 'Primary store identifier']
  store_name TEXT [not null]
  store_code TEXT [unique]
  channel channel_type [default: 'store']
  region TEXT
  province TEXT
  city TEXT
  barangay TEXT
  address TEXT
  latitude DECIMAL(10,8)
  longitude DECIMAL(11,8)
  cluster_id TEXT
  district_id TEXT
  is_active BOOLEAN [default: true]
  opened_date DATE
  closed_date DATE
  store_size_sqm INTEGER
  staff_count INTEGER
  
  // Geographic normalization columns
  citymun_psgc TEXT [note: 'Philippine Standard Geographic Code']
  province_psgc TEXT
  region_psgc TEXT
  
  created_at TIMESTAMP [default: 'NOW()']
  updated_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    store_code
    (latitude, longitude)
    citymun_psgc
    is_active
  }
}

Table scout.dim_product {
  product_id TEXT [pk]
  product_name TEXT [not null]
  product_code TEXT [unique]
  barcode TEXT
  category product_category
  subcategory TEXT
  brand TEXT
  supplier_id TEXT
  unit_of_measure TEXT
  pack_size INTEGER
  unit_cost DECIMAL(10,2)
  srp DECIMAL(10,2) [note: 'Suggested Retail Price']
  is_active BOOLEAN [default: true]
  launch_date DATE
  discontinue_date DATE
  
  created_at TIMESTAMP [default: 'NOW()']
  updated_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    product_code
    barcode
    category
    brand
    is_active
  }
}

Table scout.dim_customer {
  customer_id TEXT [pk]
  customer_code TEXT [unique]
  mobile_number TEXT
  email TEXT
  first_name TEXT
  last_name TEXT
  birthdate DATE
  gender TEXT
  customer_type customer_type
  loyalty_tier TEXT
  loyalty_points INTEGER [default: 0]
  first_purchase_date DATE
  last_purchase_date DATE
  total_lifetime_value DECIMAL(12,2)
  preferred_store_id TEXT
  preferred_payment payment_method
  
  created_at TIMESTAMP [default: 'NOW()']
  updated_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    customer_code
    mobile_number
    email
    customer_type
    loyalty_tier
  }
}

Table scout.dim_campaign {
  campaign_id TEXT [pk]
  campaign_name TEXT [not null]
  campaign_type campaign_type
  start_date DATE [not null]
  end_date DATE [not null]
  budget DECIMAL(12,2)
  target_sales DECIMAL(12,2)
  discount_percentage DECIMAL(5,2)
  discount_amount DECIMAL(10,2)
  min_purchase_amount DECIMAL(10,2)
  applicable_products TEXT[] [note: 'Array of product_ids']
  applicable_stores TEXT[] [note: 'Array of store_ids']
  is_active BOOLEAN
  
  created_at TIMESTAMP [default: 'NOW()']
  updated_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    campaign_type
    (start_date, end_date)
    is_active
  }
}

Table scout.dim_date {
  date_key DATE [pk]
  year INTEGER [not null]
  quarter INTEGER [not null]
  month INTEGER [not null]
  week INTEGER [not null]
  day_of_month INTEGER [not null]
  day_of_week INTEGER [not null]
  day_name TEXT [not null]
  month_name TEXT [not null]
  is_weekend BOOLEAN [not null]
  is_holiday BOOLEAN [default: false]
  holiday_name TEXT
  fiscal_year INTEGER
  fiscal_quarter INTEGER
  fiscal_month INTEGER
  
  Indexes {
    year
    (year, month)
    (year, quarter)
    is_holiday
  }
}

// ==========================================
// GEOGRAPHIC MASTER DATA
// ==========================================

Table scout.dim_geo_region {
  region_key TEXT [pk, note: 'Normalized region identifier']
  region_name TEXT [not null]
  region_psgc TEXT [unique]
  island_group TEXT [note: 'Luzon, Visayas, Mindanao']
  aliases TEXT[] [note: 'Alternative names (NCR, Metro Manila, etc.)']
  
  Indexes {
    region_psgc
  }
}

Table scout.dim_geo_province {
  province_psgc TEXT [pk]
  province_name TEXT [not null]
  region_key TEXT [not null]
  
  Indexes {
    region_key
  }
}

Table scout.dim_geo_citymun {
  citymun_psgc TEXT [pk]
  citymun_name TEXT [not null]
  province_psgc TEXT [not null]
  region_key TEXT [not null]
  is_city BOOLEAN [default: false]
  income_class income_class
  population INTEGER
  area_sqkm DECIMAL(10,2)
  
  Indexes {
    province_psgc
    region_key
    is_city
    income_class
  }
}

// Geographic boundary tables with PostGIS geometry
Table scout.geo_adm1_region {
  region_key TEXT [pk]
  region_name TEXT [not null]
  region_psgc TEXT
  geom GEOMETRY(MULTIPOLYGON, 4326) [not null]
  area_sqkm DECIMAL(10,2)
  population INTEGER
  created_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    geom [type: gist]
  }
}

Table scout.geo_adm2_province {
  province_psgc TEXT [pk]
  province_name TEXT [not null]
  region_key TEXT [not null]
  geom GEOMETRY(MULTIPOLYGON, 4326) [not null]
  area_sqkm DECIMAL(10,2)
  population INTEGER
  created_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    geom [type: gist]
    region_key
  }
}

Table scout.geo_adm3_citymun {
  citymun_psgc TEXT [pk]
  citymun_name TEXT [not null]
  province_psgc TEXT [not null]
  region_key TEXT [not null]
  geom GEOMETRY(MULTIPOLYGON, 4326) [not null]
  area_sqkm DECIMAL(10,2)
  population INTEGER
  created_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    geom [type: gist]
    province_psgc
    region_key
  }
}

// Simplified geometries for performance
Table scout.geo_adm1_region_gen {
  region_key TEXT [pk]
  geom GEOMETRY(MULTIPOLYGON, 4326) [not null, note: 'Simplified with ST_SimplifyPreserveTopology']
  
  Indexes {
    geom [type: gist]
  }
}

Table scout.geo_adm3_citymun_gen {
  citymun_psgc TEXT [pk]
  geom GEOMETRY(MULTIPOLYGON, 4326) [not null, note: 'Simplified geometry']
  
  Indexes {
    geom [type: gist]
  }
}

// ==========================================
// TRANSACTIONAL TABLES (Facts)
// ==========================================

Table scout.bronze_events {
  event_id UUID [pk, default: 'gen_random_uuid()']
  event_type TEXT [not null]
  event_data JSONB [not null]
  event_hash BYTEA [unique, note: 'SHA256 hash for deduplication']
  source_system TEXT
  ingested_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    event_type
    ingested_at
    event_hash
  }
}

Table scout.bronze_transactions {
  raw_id UUID [pk, default: 'gen_random_uuid()']
  transaction_data JSONB [not null]
  source_file TEXT
  loaded_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    loaded_at
  }
}

Table scout.silver_transactions {
  id UUID [pk, default: 'gen_random_uuid()']
  transaction_id TEXT [not null]
  store_id TEXT [not null]
  ts TIMESTAMP [not null]
  date_key DATE [not null]
  time_of_day time_of_day [not null]
  
  // Customer info
  customer_id TEXT
  customer_type customer_type
  
  // Transaction details
  total_amount DECIMAL(10,2) [not null]
  discount_amount DECIMAL(10,2) [default: 0]
  tax_amount DECIMAL(10,2) [default: 0]
  net_amount DECIMAL(10,2) [not null]
  payment_method payment_method
  
  // Product aggregates
  item_count INTEGER [not null]
  unique_products INTEGER [not null]
  units_per_transaction INTEGER [not null]
  basket_size INTEGER [not null]
  
  // Derived fields
  peso_value DECIMAL(10,2) [not null]
  product_category product_category
  handshake_triggered BOOLEAN [default: false]
  handshake_score DECIMAL(3,2)
  
  // Campaign tracking
  campaign_id TEXT
  campaign_influenced BOOLEAN [default: false]
  
  // Location enrichment  
  region TEXT
  province TEXT
  city TEXT
  
  // Processing metadata
  processed_at TIMESTAMP [default: 'NOW()']
  quality_score DECIMAL(3,2)
  
  Indexes {
    transaction_id
    store_id
    ts
    date_key
    customer_id
    campaign_id
    (store_id, date_key)
    (region, date_key)
  }
}

Table scout.silver_line_items {
  line_id UUID [pk, default: 'gen_random_uuid()']
  transaction_id TEXT [not null]
  product_id TEXT [not null]
  quantity INTEGER [not null]
  unit_price DECIMAL(10,2) [not null]
  line_amount DECIMAL(10,2) [not null]
  discount_amount DECIMAL(10,2) [default: 0]
  
  Indexes {
    transaction_id
    product_id
  }
}

// ==========================================
// ANALYTICAL VIEWS (Gold Layer)
// ==========================================

Table scout.gold_daily_metrics {
  date_key DATE [not null]
  store_id TEXT [not null]
  
  // Transaction metrics
  transaction_count INTEGER
  total_sales DECIMAL(12,2)
  total_discount DECIMAL(10,2)
  total_tax DECIMAL(10,2)
  net_sales DECIMAL(12,2)
  
  // Customer metrics
  unique_customers INTEGER
  new_customers INTEGER
  returning_customers INTEGER
  vip_customers INTEGER
  
  // Product metrics
  units_sold INTEGER
  unique_products_sold INTEGER
  avg_basket_size DECIMAL(5,2)
  avg_transaction_value DECIMAL(10,2)
  
  // Time distribution
  morning_sales DECIMAL(10,2)
  afternoon_sales DECIMAL(10,2)
  evening_sales DECIMAL(10,2)
  night_sales DECIMAL(10,2)
  
  // Campaign effectiveness
  campaign_transactions INTEGER
  campaign_sales DECIMAL(10,2)
  campaign_effectiveness DECIMAL(5,2)
  
  created_at TIMESTAMP [default: 'NOW()']
  
  Indexes {
    (date_key, store_id) [unique]
    date_key
    store_id
  }
}

Table scout.gold_region_choropleth {
  region_key TEXT [not null]
  region_name TEXT [not null]
  day DATE [not null]
  geom GEOMETRY(MULTIPOLYGON, 4326)
  
  // Metrics
  txn_count BIGINT
  active_stores BIGINT
  new_customers BIGINT
  peso_total DECIMAL(14,2)
  avg_transaction_value DECIMAL(10,2)
  
  // Time-based sales
  morning_sales DECIMAL(14,2)
  afternoon_sales DECIMAL(14,2)
  evening_sales DECIMAL(14,2)
  night_sales DECIMAL(14,2)
  
  // Demographics
  area_sqkm DECIMAL(10,2)
  population INTEGER
  revenue_per_capita DECIMAL(10,2)
  
  Indexes {
    (region_key, day)
    day
    geom [type: gist]
  }
}

// ==========================================
// FUNCTIONS & PROCEDURES
// ==========================================

// Event hash function for deduplication
Function scout.fn_event_hash(data JSONB) RETURNS BYTEA {
  Note: 'Generates SHA256 hash of JSON data for idempotent ingestion'
}

// Region normalization function
Function scout.norm_region(region_name TEXT) RETURNS TEXT {
  Note: 'Normalizes region names (NCR â†’ Metro Manila, IV-A â†’ CALABARZON, etc.)'
}

// City/Municipality PSGC lookup
Function scout.norm_citymun(city TEXT, province TEXT) RETURNS TEXT {
  Note: 'Returns PSGC code for city/municipality'
}

// Gold layer refresh with advisory lock
Function scout.refresh_gold() RETURNS VOID {
  Note: 'Refreshes gold layer materialized views with concurrency control'
}

// Transaction ingestion with deduplication
Function scout.ingest_transaction(data JSONB) RETURNS VOID {
  Note: 'Ingests transaction with automatic deduplication and enrichment'
}

// ==========================================
// MATERIALIZED VIEWS
// ==========================================

MaterializedView scout.mv_store_performance_30d {
  Note: 'Store performance metrics for last 30 days'
  refresh_strategy: 'CONCURRENTLY'
  refresh_interval: '1 hour'
}

MaterializedView scout.mv_product_velocity {
  Note: 'Fast-moving products by region and store'
  refresh_strategy: 'CONCURRENTLY'
  refresh_interval: '6 hours'
}

MaterializedView scout.mv_customer_segments {
  Note: 'Customer segmentation with RFM analysis'
  refresh_strategy: 'CONCURRENTLY'
  refresh_interval: 'daily'
}

// ==========================================
// RELATIONSHIPS
// ==========================================

Ref: scout.silver_transactions.store_id > scout.dim_store.store_id
Ref: scout.silver_transactions.customer_id > scout.dim_customer.customer_id
Ref: scout.silver_transactions.campaign_id > scout.dim_campaign.campaign_id
Ref: scout.silver_transactions.date_key > scout.dim_date.date_key

Ref: scout.silver_line_items.transaction_id > scout.silver_transactions.transaction_id
Ref: scout.silver_line_items.product_id > scout.dim_product.product_id

Ref: scout.dim_store.citymun_psgc > scout.dim_geo_citymun.citymun_psgc
Ref: scout.dim_geo_citymun.province_psgc > scout.dim_geo_province.province_psgc
Ref: scout.dim_geo_province.region_key > scout.dim_geo_region.region_key

Ref: scout.geo_adm1_region.region_key > scout.dim_geo_region.region_key
Ref: scout.geo_adm2_province.province_psgc > scout.dim_geo_province.province_psgc
Ref: scout.geo_adm3_citymun.citymun_psgc > scout.dim_geo_citymun.citymun_psgc

Ref: scout.gold_daily_metrics.store_id > scout.dim_store.store_id
Ref: scout.gold_daily_metrics.date_key > scout.dim_date.date_key

Ref: scout.gold_region_choropleth.region_key > scout.dim_geo_region.region_key
```

## ğŸ”„ ETL/ELT Data Flow

### 1. **Bronze Layer** (Raw Data Ingestion)
```sql
-- Raw events with deduplication
scout.bronze_events â†’ Immutable event store
scout.bronze_transactions â†’ Raw transaction JSON
scout.bronze_store_master â†’ Store metadata dumps
scout.bronze_product_catalog â†’ Product catalog imports
```

### 2. **Silver Layer** (Cleaned & Enriched)
```sql
-- Validated and enriched data
scout.silver_transactions â†’ Cleaned transactions with geographic enrichment
scout.silver_line_items â†’ Transaction line item details
scout.silver_store_metrics â†’ Real-time store performance
scout.silver_customer_segments â†’ Customer behavior analysis
```

### 3. **Gold Layer** (Business Aggregates)
```sql
-- Pre-aggregated metrics for reporting
scout.gold_daily_metrics â†’ Daily KPIs by store
scout.gold_weekly_metrics â†’ Weekly trends
scout.gold_monthly_metrics â†’ Monthly summaries
scout.gold_region_choropleth â†’ Geographic aggregates for visualization
scout.gold_product_performance â†’ Product velocity and trends
scout.gold_customer_ltv â†’ Customer lifetime value
```

### 4. **Platinum Layer** (ML Features & Advanced Analytics)
```sql
-- ML-ready features and predictions
scout.feature_store â†’ Engineered features for ML models
scout.prediction_outputs â†’ Model predictions (churn, demand, etc.)
scout.anomaly_detection â†’ Outlier detection results
scout.recommendation_engine â†’ Product recommendations
```

## ğŸš€ Quick Start

### Prerequisites
- Node.js 20+
- pnpm 9+ (`npm install -g pnpm`)
- Docker & Docker Compose
- PostgreSQL 14+ with pgvector extension
- Python 3.8+
- GitHub CLI (for releases)

### 1. Clone and Setup
```bash
git clone https://github.com/jgtolentino/ai-aas-hardened-lakehouse.git
cd ai-aas-hardened-lakehouse

# Install dependencies
pnpm install

# Setup environment
cp .env.example .env
# Edit .env with your database credentials
```

### 2. Local Development
```bash
# Start all services with Docker Compose
docker compose -f infra/docker/compose.yml up -d

# Services will be available at:
# - PostgreSQL: localhost:5432
# - API Service: http://localhost:8000
# - Worker Service: http://localhost:3000
# - Brand Model: http://localhost:8001

# Run database migrations
./scripts/setup-db.sh

# Build all packages
pnpm run build

# Run tests
pnpm run test
```

### 3. Production Deployment
```bash
# Build Docker images
pnpm run docker:build

# Run CI/CD checks locally
pnpm run ci:check

# Deploy to production
git push origin main

# Images are automatically published to GHCR:
# ghcr.io/jgtolentino/ai-aas-hardened-lakehouse-api:latest
# ghcr.io/jgtolentino/ai-aas-hardened-lakehouse-worker:latest
# ghcr.io/jgtolentino/ai-aas-hardened-lakehouse-brand-model:latest
```

## ğŸ”§ Development Workflow

### Branch Protection
The `main` branch is protected with required status checks:
- âœ… DB/Build/Test - Database migrations and build verification
- âœ… Dataset Publisher Tests - Package unit and integration tests  
- âœ… Security Scan - CodeQL and dependency scanning

### Making Changes
```bash
# Create feature branch
git checkout -b feature/your-feature

# Make changes and test locally
pnpm run dev

# Run linting and type checking
pnpm run lint
pnpm run typecheck

# Create pull request
gh pr create --title "feat: your feature" --body "Description of changes"

# After approval and checks pass, merge
gh pr merge --squash
```

### CI/CD Pipeline
1. **Pull Request**: Runs all tests and checks
2. **Merge to main**: 
   - Builds and publishes Docker images to GHCR
   - Tags with commit SHA and 'latest'
   - Deploys to staging (if configured)
3. **Release**: Create GitHub release to trigger production deployment

## ğŸ“Š Performance Metrics

### Query Performance SLAs
- **Simple aggregations**: P95 < 100ms
- **Geographic queries**: P95 < 1.5s
- **Choropleth rendering**: P95 < 2.5s end-to-end
- **Dashboard load**: P95 < 3s

### Data Pipeline SLAs
- **Ingestion latency**: < 30s from source to Bronze
- **Silver processing**: < 2 minutes
- **Gold refresh**: < 5 minutes
- **Data freshness**: < 10 minutes end-to-end

### Scale Tested
- **Transaction volume**: 100M+ records
- **Geographic coverage**: 1,600+ cities/municipalities
- **Concurrent users**: 500+
- **Storage**: 10TB+ raw data

## ğŸ” Security Features

### Database Security
- **Row-Level Security (RLS)**: Multi-tenant isolation
- **Column-Level Encryption**: PII data protection
- **Audit Logging**: Complete query audit trail
- **Secret Rotation**: Automated credential rotation

### Infrastructure Security
- **Network Policies**: Zero-trust networking
- **OPA Gatekeeper**: Policy-as-code admission control
- **mTLS**: Service-to-service encryption
- **RBAC**: Fine-grained access control

### Application Security
- **CSRF Protection**: Enabled for all state-changing operations
- **JWT Authentication**: Short-lived tokens with refresh
- **API Rate Limiting**: DDoS protection
- **Input Validation**: SQL injection prevention

## ğŸ› ï¸ Operations

### Available Scripts
```bash
# Development
pnpm run dev          # Start all services in dev mode
pnpm run build        # Build all packages
pnpm run test         # Run all tests
pnpm run lint         # Lint all code
pnpm run typecheck    # TypeScript checking

# Docker
pnpm run docker:build # Build all images
pnpm run docker:push  # Push to registry

# Database
pnpm run db:migrate   # Run migrations
pnpm run db:seed      # Seed test data
pnpm run dq:check     # Run data quality checks
```

### Service Endpoints
- **API Service**: http://localhost:8000/docs (Swagger UI)
- **Worker Service**: http://localhost:3000/health
- **Brand Model**: http://localhost:8001/docs
- **PostgreSQL**: localhost:5432

### Docker Images
Published automatically to GitHub Container Registry:
```bash
# Pull latest images
docker pull ghcr.io/jgtolentino/ai-aas-hardened-lakehouse-api:latest
docker pull ghcr.io/jgtolentino/ai-aas-hardened-lakehouse-worker:latest
docker pull ghcr.io/jgtolentino/ai-aas-hardened-lakehouse-brand-model:latest
```

## ğŸ“š Documentation

- [Architecture Overview](ARCHITECTURE_FLOW.md)
- [Monorepo Structure](docs/monorepo-structure.md)
- [CI/CD Pipeline](docs/cicd-pipeline.md)
- [Database Schema](docs/database-schema.md)
- [API Documentation](services/api/README.md)
- [Deployment Guide](DEPLOYMENT_CHECKLIST.md)
- [Security Hardening](docs/security/hardening-guide.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Install dependencies: `pnpm install`
4. Make changes and test: `pnpm run test`
5. Commit changes (`git commit -m 'feat: add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Commit Message Format
Follow conventional commits:
- `feat:` New feature
- `fix:` Bug fix
- `docs:` Documentation
- `chore:` Maintenance
- `test:` Tests
- `refactor:` Code refactoring

### Pull Request Requirements
- All CI checks must pass
- Code review approval required
- Branch must be up-to-date with main
- Commits will be squashed on merge

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

Built with best-in-class open source technologies:
- **Apache Superset** - Modern data exploration and visualization
- **PostGIS** - Spatial and geographic objects for PostgreSQL
- **Apache Trino** - Fast distributed SQL query engine
- **Apache Iceberg** - High-performance table format
- **dbt** - Transform data in your warehouse
- **MinIO** - High-performance object storage
- **Bruno** - Fast and Git-friendly API client

Special thanks to the Philippine Statistics Authority for PSGC geographic codes.

## ğŸš¨ Recent Updates

### v2.0.0 - Monorepo Migration (January 2025)
- Migrated from submodules to production-grade monorepo structure
- Implemented pnpm workspaces + Turborepo for build orchestration
- Added comprehensive CI/CD with GitHub Actions
- Set up automated Docker image publishing to GHCR
- Implemented branch protection with required status checks
- Stabilized all workflows and fixed dependency issues

---

ğŸš€ **Production Grade Monorepo** | ğŸ” **Enterprise Hardened** | ğŸŒ **Geographic Enabled** | ğŸ“Š **Complete Data Stack**

For questions or support, please open an issue or contact the maintainers.

<!-- AUTO-GEN:STRUCTURE START -->
## Project Structure (auto)

```
project-root/
â”œâ”€ apps/
â”‚  â”œâ”€ docs/
â”‚  â”œâ”€ pi-edge/
â”‚  â”‚  â”œâ”€ docs/
â”‚  â”‚  â”œâ”€ edge-device/
â”‚  â”‚  â”œâ”€ fixtures/
â”‚  â”‚  â”œâ”€ node_modules/
â”‚  â”‚  â”œâ”€ packages/
â”‚  â”‚  â”œâ”€ platform/
â”‚  â”‚  â”œâ”€ public/
â”‚  â”‚  â”œâ”€ samples/
â”‚  â”‚  â”œâ”€ scripts/
â”‚  â”‚  â”œâ”€ sql/
â”‚  â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ supabase/
â”‚  â”œâ”€ scout-dashboard/
â”‚  â”‚  â”œâ”€ node_modules/
â”œâ”€ services/
â”‚  â”œâ”€ api/
â”‚  â”‚  â”œâ”€ node_modules/
â”‚  â”œâ”€ brand-model/
â”‚  â”œâ”€ worker/
â”‚  â”‚  â”œâ”€ node_modules/
â”œâ”€ packages/
â”‚  â”œâ”€ contracts/
â”‚  â”‚  â”œâ”€ node_modules/
â”‚  â”‚  â”œâ”€ sql/
â”‚  â”‚  â”œâ”€ src/
â”‚  â”œâ”€ services/
â”‚  â”‚  â”œâ”€ src/
â”‚  â”œâ”€ shared-types/
â”‚  â”œâ”€ types/
â”‚  â”œâ”€ utils-js/
â”‚  â”œâ”€ utils-py/
â”œâ”€ db/
â”‚  â”œâ”€ migrations/
â”‚  â”œâ”€ seeds/
â”‚  â”œâ”€ tests/
â”œâ”€ dq/
â”‚  â”œâ”€ checks/
â”‚  â”œâ”€ views/
â”œâ”€ supabase/
â”‚  â”œâ”€ config/
â”‚  â”œâ”€ functions/
â”‚  â”‚  â”œâ”€ export-platinum/
â”‚  â”‚  â”œâ”€ ingest-bronze/
â”‚  â”œâ”€ migrations/
â”‚  â”œâ”€ storage/
â”œâ”€ infra/
â”‚  â”œâ”€ docker/
â”‚  â”œâ”€ k8s/
â”‚  â”‚  â”œâ”€ base/
â”‚  â”‚  â”œâ”€ overlays/
â”‚  â”œâ”€ terraform/
â”‚  â”‚  â”œâ”€ envs/
â”‚  â”‚  â”œâ”€ modules/
â”œâ”€ monitoring/
â”‚  â”œâ”€ grafana-dashboards/
â”‚  â”œâ”€ prometheus/
â”œâ”€ security/
â”‚  â”œâ”€ policies/
â”‚  â”œâ”€ sops/
â”‚  â”œâ”€ threat-model/
â”œâ”€ .github/workflows/
```

<!-- AUTO-GEN:STRUCTURE END -->

<!-- AUTO-GEN:SERVICES START -->
## Services & Ports (auto)

| Service | Exposed Ports |
|---|---|
| `postgres` | 5432->5432 |
| `api` | 8000->8000 |
| `worker` | 3000->3000 |
| `brand-model` | 8001->8001 |


<!-- AUTO-GEN:SERVICES END -->

<!-- AUTO-GEN:WORKFLOWS START -->
## Active Workflows (auto)

- `ci.yml`
- `dataset-publisher-tests.yml`
- `edge-functions.yml`
- `readme-guard.yml`
- `release-images.yml`
- `security-scan.yml`
- `storage-buckets.yml`

<!-- AUTO-GEN:WORKFLOWS END -->
