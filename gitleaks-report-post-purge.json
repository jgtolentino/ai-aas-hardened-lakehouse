[
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 7,
  "EndLine": 7,
  "StartColumn": 15,
  "EndColumn": 58,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "scripts/vercel-supabase-one-liner.sh",
  "SymlinkFile": "",
  "Commit": "7bef09b75f254451b537ce5e8d2837e6ab8af0f5",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:57:19Z",
  "Message": "feat: add Vercel Supabase environment setup scripts",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "7bef09b75f254451b537ce5e8d2837e6ab8af0f5:scripts/vercel-supabase-one-liner.sh:supabase-access-token:7"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 7,
  "EndLine": 7,
  "StartColumn": 15,
  "EndColumn": 58,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "scripts/setup-vercel-supabase.sh",
  "SymlinkFile": "",
  "Commit": "7bef09b75f254451b537ce5e8d2837e6ab8af0f5",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:57:19Z",
  "Message": "feat: add Vercel Supabase environment setup scripts",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "7bef09b75f254451b537ce5e8d2837e6ab8af0f5:scripts/setup-vercel-supabase.sh:supabase-access-token:7"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 82,
  "EndLine": 82,
  "StartColumn": 12,
  "EndColumn": 24,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "DOCUMENTATION.md",
  "SymlinkFile": "",
  "Commit": "f29d0f46212825fc0537ec8da1b570bdc40dd50b",
  "Entropy": 3.180833,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T18:16:23Z",
  "Message": "ci: add ci/security workflows and vercel deploy",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "f29d0f46212825fc0537ec8da1b570bdc40dd50b:DOCUMENTATION.md:generic-bearer:82"
 },
 {
  "RuleID": "mapbox-token",
  "Description": "Mapbox public/private token",
  "StartLine": 12,
  "EndLine": 12,
  "StartColumn": 21,
  "EndColumn": 91,
  "Match": "REDACTED.eyJ1Ijoiamd0b2xlbnRpbm8iLCJhIjoiY21jMmNycWRiMDc0ajJqcHZoaDYyeTJ1NiJ9",
  "Secret": "REDACTED",
  "File": "platform/k8s/secrets/superset-mapbox-secret.yaml",
  "SymlinkFile": "",
  "Commit": "f29d0f46212825fc0537ec8da1b570bdc40dd50b",
  "Entropy": 1,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T18:16:23Z",
  "Message": "ci: add ci/security workflows and vercel deploy",
  "Tags": [
   "mapbox",
   "token"
  ],
  "Fingerprint": "f29d0f46212825fc0537ec8da1b570bdc40dd50b:platform/k8s/secrets/superset-mapbox-secret.yaml:mapbox-token:12"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 21,
  "EndColumn": 228,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "smoke-test-semantic-layer.sh",
  "SymlinkFile": "",
  "Commit": "f29d0f46212825fc0537ec8da1b570bdc40dd50b",
  "Entropy": 5.5053186,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T18:16:23Z",
  "Message": "ci: add ci/security workflows and vercel deploy",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "f29d0f46212825fc0537ec8da1b570bdc40dd50b:smoke-test-semantic-layer.sh:supabase-service-role:8"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 11,
  "EndLine": 11,
  "StartColumn": 36,
  "EndColumn": 79,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": ".mcp.json",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:.mcp.json:supabase-access-token:11"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 30,
  "EndLine": 30,
  "StartColumn": 27,
  "EndColumn": 70,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SKU_CATALOG_AUTO_DEPLOYMENT_COMPLETE.md",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:SKU_CATALOG_AUTO_DEPLOYMENT_COMPLETE.md:supabase-access-token:30"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 100,
  "EndLine": 100,
  "StartColumn": 9,
  "EndColumn": 52,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "TASKS_COMPLETION_SUMMARY.md",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 3.9905863,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:TASKS_COMPLETION_SUMMARY.md:supabase-access-token:100"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 18,
  "EndLine": 18,
  "StartColumn": 36,
  "EndColumn": 79,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "qa/mcp/mcp.json",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:qa/mcp/mcp.json:supabase-access-token:18"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 75,
  "EndLine": 75,
  "StartColumn": 33,
  "EndColumn": 76,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/MCP_CONFIGURATION.md",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:platform/scout/MCP_CONFIGURATION.md:supabase-access-token:75"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 88,
  "EndLine": 88,
  "StartColumn": 34,
  "EndColumn": 77,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/MCP_CONFIGURATION.md",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:platform/scout/MCP_CONFIGURATION.md:supabase-access-token:88"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 21,
  "EndColumn": 228,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "scripts/create_seed_buckets_and_upload.sh",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 5.46117,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:scripts/create_seed_buckets_and_upload.sh:supabase-service-role:8"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 9,
  "EndLine": 9,
  "StartColumn": 24,
  "EndColumn": 242,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "scripts/create_seed_buckets_and_upload.sh",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 5.446655,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:scripts/create_seed_buckets_and_upload.sh:supabase-service-role:9"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 5,
  "EndLine": 5,
  "StartColumn": 32,
  "EndColumn": 75,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "start-claude-mcp.sh",
  "SymlinkFile": "",
  "Commit": "d42e4a936e27fd62a354b35b0125e70f5f709496",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "d42e4a936e27fd62a354b35b0125e70f5f709496:start-claude-mcp.sh:supabase-access-token:5"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 11,
  "EndLine": 11,
  "StartColumn": 36,
  "EndColumn": 79,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": ".mcp.json",
  "SymlinkFile": "",
  "Commit": "fac6059531be9dfa22c6baba6dc6ef40f3cb3f8b",
  "Entropy": 3.9540036,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:48:18Z",
  "Message": "feat: complete Scout v5.2 backend deployment with agentic analytics\n\n- Add comprehensive agentic analytics infrastructure\n- Deploy Scout v5.2 backend with complete schema alignment\n- Add AI orchestration guides and deployment scripts\n- Implement MCP GitHub integration for automated workflows\n- Add production deployment validation scripts\n- Complete documentation for all new features\n- Add Suqi Chat API integration\n- Deploy Isko worker functions for data processing\n\nThis completes the Scout v5.2 backend deployment with full agentic capabilities",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "fac6059531be9dfa22c6baba6dc6ef40f3cb3f8b:.mcp.json:supabase-access-token:11"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 77,
  "EndLine": 77,
  "StartColumn": 23,
  "EndColumn": 42,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "docs-site/docs/api-reference/suqi-chat-api.md",
  "SymlinkFile": "",
  "Commit": "fac6059531be9dfa22c6baba6dc6ef40f3cb3f8b",
  "Entropy": 3.3464394,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:48:18Z",
  "Message": "feat: complete Scout v5.2 backend deployment with agentic analytics\n\n- Add comprehensive agentic analytics infrastructure\n- Deploy Scout v5.2 backend with complete schema alignment\n- Add AI orchestration guides and deployment scripts\n- Implement MCP GitHub integration for automated workflows\n- Add production deployment validation scripts\n- Complete documentation for all new features\n- Add Suqi Chat API integration\n- Deploy Isko worker functions for data processing\n\nThis completes the Scout v5.2 backend deployment with full agentic capabilities",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "fac6059531be9dfa22c6baba6dc6ef40f3cb3f8b:docs-site/docs/api-reference/suqi-chat-api.md:generic-bearer:77"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 236,
  "EndLine": 236,
  "StartColumn": 23,
  "EndColumn": 42,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "docs-site/docs/api-reference/suqi-chat-api.md",
  "SymlinkFile": "",
  "Commit": "fac6059531be9dfa22c6baba6dc6ef40f3cb3f8b",
  "Entropy": 3.3464394,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:48:18Z",
  "Message": "feat: complete Scout v5.2 backend deployment with agentic analytics\n\n- Add comprehensive agentic analytics infrastructure\n- Deploy Scout v5.2 backend with complete schema alignment\n- Add AI orchestration guides and deployment scripts\n- Implement MCP GitHub integration for automated workflows\n- Add production deployment validation scripts\n- Complete documentation for all new features\n- Add Suqi Chat API integration\n- Deploy Isko worker functions for data processing\n\nThis completes the Scout v5.2 backend deployment with full agentic capabilities",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "fac6059531be9dfa22c6baba6dc6ef40f3cb3f8b:docs-site/docs/api-reference/suqi-chat-api.md:generic-bearer:236"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 32,
  "EndLine": 32,
  "StartColumn": 20,
  "EndColumn": 227,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SUPABASE_SYNC_GUIDE.md",
  "SymlinkFile": "",
  "Commit": "3d27e135ae11eaaa7eab25eb908469c2748a3a94",
  "Entropy": 5.5702257,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "3d27e135ae11eaaa7eab25eb908469c2748a3a94:SUPABASE_SYNC_GUIDE.md:supabase-service-role:32"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 33,
  "EndLine": 33,
  "StartColumn": 28,
  "EndColumn": 246,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SUPABASE_SYNC_GUIDE.md",
  "SymlinkFile": "",
  "Commit": "3d27e135ae11eaaa7eab25eb908469c2748a3a94",
  "Entropy": 5.3627667,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "3d27e135ae11eaaa7eab25eb908469c2748a3a94:SUPABASE_SYNC_GUIDE.md:supabase-service-role:33"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 34,
  "EndLine": 34,
  "StartColumn": 24,
  "EndColumn": 67,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SUPABASE_SYNC_GUIDE.md",
  "SymlinkFile": "",
  "Commit": "3d27e135ae11eaaa7eab25eb908469c2748a3a94",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "3d27e135ae11eaaa7eab25eb908469c2748a3a94:SUPABASE_SYNC_GUIDE.md:supabase-access-token:34"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 4,
  "EndLine": 4,
  "StartColumn": 69,
  "EndColumn": 276,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "services/dashboard/src/config/supabase.ts",
  "SymlinkFile": "",
  "Commit": "3d27e135ae11eaaa7eab25eb908469c2748a3a94",
  "Entropy": 5.5702257,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "3d27e135ae11eaaa7eab25eb908469c2748a3a94:services/dashboard/src/config/supabase.ts:supabase-service-role:4"
 },
 {
  "RuleID": "supabase-access-token",
  "Description": "Supabase access token",
  "StartLine": 74,
  "EndLine": 74,
  "StartColumn": 34,
  "EndColumn": 77,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/MCP_CONFIGURATION.md",
  "SymlinkFile": "",
  "Commit": "f4f9163d74f41c80ae34b96b1298392c2dd74b7e",
  "Entropy": 3.9540036,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T08:35:20Z",
  "Message": "feat: Add scout-databank as submodule with MCP configuration\n\n- Integrated scout-databank-isolated as git submodule at platform/scout/scout-databank/\n- Added comprehensive MCP configuration documentation\n- Configured Playwright and Puppeteer MCP servers for automated testing\n- Documented AI reasoning tracking capabilities\n- Updated platform README with new integrations",
  "Tags": [
   "supabase",
   "token"
  ],
  "Fingerprint": "f4f9163d74f41c80ae34b96b1298392c2dd74b7e:platform/scout/MCP_CONFIGURATION.md:supabase-access-token:74"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 4,
  "EndLine": 4,
  "StartColumn": 25,
  "EndColumn": 232,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/.env.local",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/.env.local:supabase-service-role:4"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 32,
  "EndColumn": 239,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/.env.local",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/.env.local:supabase-service-role:8"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 23,
  "EndLine": 23,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:23"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 51,
  "EndLine": 51,
  "StartColumn": 31,
  "EndColumn": 238,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:51"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 68,
  "EndLine": 68,
  "StartColumn": 42,
  "EndColumn": 249,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:68"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 106,
  "EndLine": 106,
  "StartColumn": 59,
  "EndColumn": 266,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:106"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 134,
  "EndLine": 134,
  "StartColumn": 5,
  "EndColumn": 212,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:134"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 179,
  "EndLine": 179,
  "StartColumn": 4,
  "EndColumn": 15,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/README.md",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 3.0220551,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/README.md:generic-bearer:179"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 10,
  "EndLine": 10,
  "StartColumn": 44,
  "EndColumn": 251,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/public/index.html",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/public/index.html:supabase-service-role:10"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 6,
  "EndLine": 6,
  "StartColumn": 24,
  "EndColumn": 231,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/public/runtime-env.js",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/public/runtime-env.js:supabase-service-role:6"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 45,
  "EndLine": 45,
  "StartColumn": 7,
  "EndColumn": 214,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "apps/pi-edge/src/lib/supabase.ts",
  "SymlinkFile": "",
  "Commit": "23c8520c48a53f0761aa525611f249cb4d2bbf1e",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice â†’ scout-edge-ingest â†’ scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing â†’ Multi-layered brand resolution\n- No product structure â†’ SKU scraping and catalog integration\n- No quality metrics â†’ Confusion matrix and F1 scoring\n- No demographics â†’ Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "23c8520c48a53f0761aa525611f249cb4d2bbf1e:apps/pi-edge/src/lib/supabase.ts:supabase-service-role:45"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 12,
  "EndLine": 12,
  "StartColumn": 66,
  "EndColumn": 77,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "supabase/functions/jwt-echo/index.ts",
  "SymlinkFile": "",
  "Commit": "953a20be579e7c2a095b78a0d012efc741308eff",
  "Entropy": 3.0220551,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\nðŸš€ MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\nâœ… Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\nâœ… Function Deployment: 4/4 edge functions ACTIVE\nâœ… Working End-to-End: isko-scraper fully operational\nâœ… Error Handling: Structured JSON responses\nâœ… Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: âœ… JWT validation \u0026 decode\n- isko-scraper: âœ… Complete scraping pipeline\n- quality-sentinel: ðŸ”§ Auth ready, needs DB schema\n- scout-edge-ingest: ðŸ”§ Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\nðŸŽ¯ Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "953a20be579e7c2a095b78a0d012efc741308eff:supabase/functions/jwt-echo/index.ts:generic-bearer:12"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 36,
  "EndLine": 36,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SHIP-INSTRUCTIONS.md",
  "SymlinkFile": "",
  "Commit": "953a20be579e7c2a095b78a0d012efc741308eff",
  "Entropy": 5.5702257,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\nðŸš€ MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\nâœ… Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\nâœ… Function Deployment: 4/4 edge functions ACTIVE\nâœ… Working End-to-End: isko-scraper fully operational\nâœ… Error Handling: Structured JSON responses\nâœ… Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: âœ… JWT validation \u0026 decode\n- isko-scraper: âœ… Complete scraping pipeline\n- quality-sentinel: ðŸ”§ Auth ready, needs DB schema\n- scout-edge-ingest: ðŸ”§ Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\nðŸŽ¯ Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "953a20be579e7c2a095b78a0d012efc741308eff:SHIP-INSTRUCTIONS.md:supabase-service-role:36"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 42,
  "EndLine": 42,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SHIP-INSTRUCTIONS.md",
  "SymlinkFile": "",
  "Commit": "953a20be579e7c2a095b78a0d012efc741308eff",
  "Entropy": 5.5702257,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\nðŸš€ MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\nâœ… Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\nâœ… Function Deployment: 4/4 edge functions ACTIVE\nâœ… Working End-to-End: isko-scraper fully operational\nâœ… Error Handling: Structured JSON responses\nâœ… Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: âœ… JWT validation \u0026 decode\n- isko-scraper: âœ… Complete scraping pipeline\n- quality-sentinel: ðŸ”§ Auth ready, needs DB schema\n- scout-edge-ingest: ðŸ”§ Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\nðŸŽ¯ Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "953a20be579e7c2a095b78a0d012efc741308eff:SHIP-INSTRUCTIONS.md:supabase-service-role:42"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 36,
  "EndLine": 36,
  "StartColumn": 23,
  "EndColumn": 237,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SHIP-INSTRUCTIONS.md",
  "SymlinkFile": "",
  "Commit": "953a20be579e7c2a095b78a0d012efc741308eff",
  "Entropy": 5.6174765,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\nðŸš€ MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\nâœ… Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\nâœ… Function Deployment: 4/4 edge functions ACTIVE\nâœ… Working End-to-End: isko-scraper fully operational\nâœ… Error Handling: Structured JSON responses\nâœ… Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: âœ… JWT validation \u0026 decode\n- isko-scraper: âœ… Complete scraping pipeline\n- quality-sentinel: ðŸ”§ Auth ready, needs DB schema\n- scout-edge-ingest: ðŸ”§ Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\nðŸŽ¯ Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "953a20be579e7c2a095b78a0d012efc741308eff:SHIP-INSTRUCTIONS.md:generic-bearer:36"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 42,
  "EndLine": 42,
  "StartColumn": 23,
  "EndColumn": 237,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "SHIP-INSTRUCTIONS.md",
  "SymlinkFile": "",
  "Commit": "953a20be579e7c2a095b78a0d012efc741308eff",
  "Entropy": 5.6174765,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\nðŸš€ MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\nâœ… Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\nâœ… Function Deployment: 4/4 edge functions ACTIVE\nâœ… Working End-to-End: isko-scraper fully operational\nâœ… Error Handling: Structured JSON responses\nâœ… Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: âœ… JWT validation \u0026 decode\n- isko-scraper: âœ… Complete scraping pipeline\n- quality-sentinel: ðŸ”§ Auth ready, needs DB schema\n- scout-edge-ingest: ðŸ”§ Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\nðŸŽ¯ Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "953a20be579e7c2a095b78a0d012efc741308eff:SHIP-INSTRUCTIONS.md:generic-bearer:42"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 4,
  "EndLine": 4,
  "StartColumn": 25,
  "EndColumn": 232,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": ".env.local",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:.env.local:supabase-service-role:4"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 32,
  "EndColumn": 239,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": ".env.local",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:.env.local:supabase-service-role:8"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 10,
  "EndLine": 10,
  "StartColumn": 44,
  "EndColumn": 251,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "public/index.html",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:public/index.html:supabase-service-role:10"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 6,
  "EndLine": 6,
  "StartColumn": 24,
  "EndColumn": 231,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "public/runtime-env.js",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:public/runtime-env.js:supabase-service-role:6"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 23,
  "EndLine": 23,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:23"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 51,
  "EndLine": 51,
  "StartColumn": 31,
  "EndColumn": 238,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:51"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 68,
  "EndLine": 68,
  "StartColumn": 42,
  "EndColumn": 249,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:68"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 106,
  "EndLine": 106,
  "StartColumn": 59,
  "EndColumn": 266,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:106"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 134,
  "EndLine": 134,
  "StartColumn": 5,
  "EndColumn": 212,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-service-role:134"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 45,
  "EndLine": 45,
  "StartColumn": 7,
  "EndColumn": 214,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "src/lib/supabase.ts",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:src/lib/supabase.ts:supabase-service-role:45"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 179,
  "EndLine": 179,
  "StartColumn": 4,
  "EndColumn": 15,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "README.md",
  "SymlinkFile": "",
  "Commit": "2dde35e565809b2db8bdee89c368b7a6c51a2766",
  "Entropy": 3.0220551,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T18:12:34Z",
  "Message": "feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "2dde35e565809b2db8bdee89c368b7a6c51a2766:README.md:generic-bearer:179"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 19,
  "EndLine": 19,
  "StartColumn": 37,
  "EndColumn": 255,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "manual-deploy-guide.md",
  "SymlinkFile": "",
  "Commit": "54b63d8acc821408d0be1fb19859a608fc05fd8d",
  "Entropy": 5.505615,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-12T17:34:52Z",
  "Message": "fix: gate production workflows to main branch with secret checks\n\n- Update ci-production.yml to only run on main branch pushes\n- Add git safe.directory configuration for full history checkout\n- Update publish-datasets.yml with secret availability checks\n- Update backup-restore.yml with proper secret gating\n- Switch from npm to pnpm for consistent workspace management\n\nFixes git exit code 128 errors when production workflows run on PRs without secrets.\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "54b63d8acc821408d0be1fb19859a608fc05fd8d:manual-deploy-guide.md:supabase-service-role:19"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 20,
  "EndLine": 20,
  "StartColumn": 15,
  "EndColumn": 205,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "orchestration/lyra/scripts/learning/test-samples.js",
  "SymlinkFile": "",
  "Commit": "54b63d8acc821408d0be1fb19859a608fc05fd8d",
  "Entropy": 5.4472847,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-12T17:34:52Z",
  "Message": "fix: gate production workflows to main branch with secret checks\n\n- Update ci-production.yml to only run on main branch pushes\n- Add git safe.directory configuration for full history checkout\n- Update publish-datasets.yml with secret availability checks\n- Update backup-restore.yml with proper secret gating\n- Switch from npm to pnpm for consistent workspace management\n\nFixes git exit code 128 errors when production workflows run on PRs without secrets.\n\nðŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "54b63d8acc821408d0be1fb19859a608fc05fd8d:orchestration/lyra/scripts/learning/test-samples.js:supabase-service-role:20"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 29,
  "EndLine": 29,
  "StartColumn": 115,
  "EndColumn": 373,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "scripts/process-edge-inbox.js",
  "SymlinkFile": "",
  "Commit": "391becec6efb56076cc4402bc330cd80803cefd7",
  "Entropy": 5.6437235,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-11T17:27:00Z",
  "Message": "feat: add ETL processor and fix PhilippinesMap component\n\n- Added process-edge-inbox.js script to handle edge-inbox ZIP files\n- Fixed PhilippinesMap.tsx runtime error with proper error handling\n- Script processes json.zip and scoutpi-0003.zip from storage bucket\n- Supports Bronze â†’ Silver â†’ Gold â†’ Platinum pipeline processing",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "391becec6efb56076cc4402bc330cd80803cefd7:scripts/process-edge-inbox.js:supabase-service-role:29"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 33,
  "EndLine": 33,
  "StartColumn": 123,
  "EndColumn": 391,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "scripts/process-edge-inbox.js",
  "SymlinkFile": "",
  "Commit": "391becec6efb56076cc4402bc330cd80803cefd7",
  "Entropy": 5.619755,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-11T17:27:00Z",
  "Message": "feat: add ETL processor and fix PhilippinesMap component\n\n- Added process-edge-inbox.js script to handle edge-inbox ZIP files\n- Fixed PhilippinesMap.tsx runtime error with proper error handling\n- Script processes json.zip and scoutpi-0003.zip from storage bucket\n- Supports Bronze â†’ Silver â†’ Gold â†’ Platinum pipeline processing",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "391becec6efb56076cc4402bc330cd80803cefd7:scripts/process-edge-inbox.js:supabase-service-role:33"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 60,
  "EndLine": 60,
  "StartColumn": 32,
  "EndColumn": 55,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "scripts/deploy-token-functions.sh",
  "SymlinkFile": "",
  "Commit": "80d080f1887fb3750756c8b2f88ab439dd710f5e",
  "Entropy": 3.8868423,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-11T03:31:13Z",
  "Message": "âœ… Complete 100% project implementation - All 61 tasks done\n\n- Dataset usage analytics dashboard with comprehensive tracking\n- Dataset versioning and rollback mechanism with semantic versioning\n- Cross-region replication system for global availability\n- Dataset subscription notifications with multi-channel support\n- Complete test suites and deployment automation\n- All Edge Functions and database schemas implemented\n- Production-ready with monitoring and security features\n\nTotal completion: 61/61 tasks (100%)\n- High Priority: 17/17 âœ…\n- Medium Priority: 25/25 âœ…\n- Low Priority: 19/19 âœ…",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "80d080f1887fb3750756c8b2f88ab439dd710f5e:scripts/deploy-token-functions.sh:generic-bearer:60"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 535,
  "EndLine": 535,
  "StartColumn": 23,
  "EndColumn": 42,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "API_DOCUMENTATION.md",
  "SymlinkFile": "",
  "Commit": "8d43699ccf51514273eff5bf59c4f1d5b749e39b",
  "Entropy": 3.3464394,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T11:49:44Z",
  "Message": "docs: add comprehensive API documentation\n\n- Complete authentication guide with API key usage\n- Edge Functions API with all 4 endpoints documented\n- Database REST API (PostgREST) documentation\n- Analytics endpoints for executive dashboards\n- Real-time subscriptions with WebSocket examples\n- Error handling and HTTP status codes\n- Rate limiting information\n- SDK examples in JavaScript, Python, and cURL\n- Migration guide from v1 to v2 API\n\nThis provides developers with everything needed to integrate\nwith the Scout Analytics Platform API.",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "8d43699ccf51514273eff5bf59c4f1d5b749e39b:API_DOCUMENTATION.md:generic-bearer:535"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 540,
  "EndLine": 540,
  "StartColumn": 23,
  "EndColumn": 42,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "API_DOCUMENTATION.md",
  "SymlinkFile": "",
  "Commit": "8d43699ccf51514273eff5bf59c4f1d5b749e39b",
  "Entropy": 3.3464394,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T11:49:44Z",
  "Message": "docs: add comprehensive API documentation\n\n- Complete authentication guide with API key usage\n- Edge Functions API with all 4 endpoints documented\n- Database REST API (PostgREST) documentation\n- Analytics endpoints for executive dashboards\n- Real-time subscriptions with WebSocket examples\n- Error handling and HTTP status codes\n- Rate limiting information\n- SDK examples in JavaScript, Python, and cURL\n- Migration guide from v1 to v2 API\n\nThis provides developers with everything needed to integrate\nwith the Scout Analytics Platform API.",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "8d43699ccf51514273eff5bf59c4f1d5b749e39b:API_DOCUMENTATION.md:generic-bearer:540"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic Bearer token",
  "StartLine": 186,
  "EndLine": 186,
  "StartColumn": 79,
  "EndColumn": 93,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "Makefile",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Entropy": 3.189898,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronzeâ†’Silverâ†’Goldâ†’Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset â‡„ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\nðŸŒ Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\nðŸ” Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\nðŸ“Š Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\nðŸš€ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "bearer",
   "generic"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:Makefile:generic-bearer:186"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 7,
  "EndLine": 7,
  "StartColumn": 23,
  "EndColumn": 197,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/bruno/environments/production.bru",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Entropy": 5.385202,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronzeâ†’Silverâ†’Goldâ†’Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset â‡„ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\nðŸŒ Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\nðŸ” Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\nðŸ“Š Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\nðŸš€ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments/production.bru:supabase-service-role:7"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 26,
  "EndColumn": 210,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/bruno/environments/production.bru",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Entropy": 5.3906116,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronzeâ†’Silverâ†’Goldâ†’Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset â‡„ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\nðŸŒ Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\nðŸ” Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\nðŸ“Š Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\nðŸš€ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments/production.bru:supabase-service-role:8"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 5,
  "EndLine": 5,
  "StartColumn": 30,
  "EndColumn": 248,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/bruno/environments.json",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Entropy": 5.505615,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronzeâ†’Silverâ†’Goldâ†’Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset â‡„ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\nðŸŒ Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\nðŸ” Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\nðŸ“Š Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\nðŸš€ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments.json:supabase-service-role:5"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 6,
  "EndLine": 6,
  "StartColumn": 26,
  "EndColumn": 233,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/bruno/environments.json",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Entropy": 5.4883657,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronzeâ†’Silverâ†’Goldâ†’Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset â‡„ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\nðŸŒ Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\nðŸ” Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\nðŸ“Š Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\nðŸš€ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments.json:supabase-service-role:6"
 },
 {
  "RuleID": "supabase-service-role",
  "Description": "Supabase service role key",
  "StartLine": 19,
  "EndLine": 19,
  "StartColumn": 26,
  "EndColumn": 233,
  "Match": "REDACTED",
  "Secret": "REDACTED",
  "File": "platform/scout/bruno/environments.json",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Entropy": 5.4883657,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronzeâ†’Silverâ†’Goldâ†’Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset â‡„ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\nðŸŒ Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\nðŸ” Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\nðŸ“Š Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\nðŸš€ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "supabase",
   "key",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments.json:supabase-service-role:19"
 },
 {
  "RuleID": "mapbox-token",
  "Description": "Mapbox public/private token",
  "StartLine": 17,
  "EndLine": 17,
  "StartColumn": 36,
  "EndColumn": 106,
  "Match": "REDACTED.eyJ1Ijoiamd0b2xlbnRpbm8iLCJhIjoiY21jMmNycWRiMDc0ajJqcHZoaDYyeTJ1NiJ9",
  "Secret": "REDACTED",
  "File": "scripts/verify_choropleth_complete.sh",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Entropy": 1,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronzeâ†’Silverâ†’Goldâ†’Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset â‡„ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\nðŸŒ Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\nðŸ” Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\nðŸ“Š Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\nðŸš€ Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "mapbox",
   "token"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:scripts/verify_choropleth_complete.sh:mapbox-token:17"
 }
]
