[
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 7,
  "EndLine": 7,
  "StartColumn": 15,
  "EndColumn": 58,
  "Match": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "Secret": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "File": "scripts/setup-vercel-supabase.sh",
  "SymlinkFile": "",
  "Commit": "4a51476266731a629ca86d32a340f135025defb2",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4a51476266731a629ca86d32a340f135025defb2/scripts/setup-vercel-supabase.sh#L7",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:57:19Z",
  "Message": "feat: add Vercel Supabase environment setup scripts",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4a51476266731a629ca86d32a340f135025defb2:scripts/setup-vercel-supabase.sh:supabase-key:7"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 7,
  "EndLine": 7,
  "StartColumn": 15,
  "EndColumn": 58,
  "Match": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "Secret": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "File": "scripts/vercel-supabase-one-liner.sh",
  "SymlinkFile": "",
  "Commit": "4a51476266731a629ca86d32a340f135025defb2",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4a51476266731a629ca86d32a340f135025defb2/scripts/vercel-supabase-one-liner.sh#L7",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:57:19Z",
  "Message": "feat: add Vercel Supabase environment setup scripts",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4a51476266731a629ca86d32a340f135025defb2:scripts/vercel-supabase-one-liner.sh:supabase-key:7"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 2,
  "EndLine": 2,
  "StartColumn": 35,
  "EndColumn": 78,
  "Match": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "Secret": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "File": ".env",
  "SymlinkFile": "",
  "Commit": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/5d53f74d1c6c2995e1418c22881e315f04dc0e0d/.env#L2",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:53:24Z",
  "Message": "fix(supabase): update project reference and JWT tokens",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d:.env:supabase-key:2"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 3,
  "EndLine": 3,
  "StartColumn": 24,
  "EndColumn": 67,
  "Match": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "Secret": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "File": ".env",
  "SymlinkFile": "",
  "Commit": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/5d53f74d1c6c2995e1418c22881e315f04dc0e0d/.env#L3",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:53:24Z",
  "Message": "fix(supabase): update project reference and JWT tokens",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d:.env:supabase-key:3"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 4,
  "EndLine": 4,
  "StartColumn": 32,
  "EndColumn": 239,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlsd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MDU2MzA2OTgsImV4cCI6MjAyMTIwNjY5OH0.z6C8bEd2vF7VhxgJVl4fKf6zFMxgVlmMNjOwfJD_D6Y",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlsd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MDU2MzA2OTgsImV4cCI6MjAyMTIwNjY5OH0.z6C8bEd2vF7VhxgJVl4fKf6zFMxgVlmMNjOwfJD_D6Y",
  "File": ".env",
  "SymlinkFile": "",
  "Commit": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/5d53f74d1c6c2995e1418c22881e315f04dc0e0d/.env#L4",
  "Entropy": 5.4936256,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:53:24Z",
  "Message": "fix(supabase): update project reference and JWT tokens",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d:.env:supabase-key:4"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 5,
  "EndLine": 5,
  "StartColumn": 28,
  "EndColumn": 246,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NTIwNjMzNCwiZXhwIjoyMDcwNzgyMzM0fQ.vB9MIfInzX-ch4Kzb-d0_0ndNm-id1MVgQZuDBmtrdw",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NTIwNjMzNCwiZXhwIjoyMDcwNzgyMzM0fQ.vB9MIfInzX-ch4Kzb-d0_0ndNm-id1MVgQZuDBmtrdw",
  "File": ".env",
  "SymlinkFile": "",
  "Commit": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/5d53f74d1c6c2995e1418c22881e315f04dc0e0d/.env#L5",
  "Entropy": 5.3627667,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:53:24Z",
  "Message": "fix(supabase): update project reference and JWT tokens",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d:.env:supabase-key:5"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 6,
  "EndLine": 6,
  "StartColumn": 23,
  "EndColumn": 66,
  "Match": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "Secret": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "File": ".env",
  "SymlinkFile": "",
  "Commit": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/5d53f74d1c6c2995e1418c22881e315f04dc0e0d/.env#L6",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:53:24Z",
  "Message": "fix(supabase): update project reference and JWT tokens",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d:.env:supabase-key:6"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 9,
  "EndLine": 9,
  "StartColumn": 40,
  "EndColumn": 83,
  "Match": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "Secret": "sbp_830d652c8d86db9dd9a7e907f1c6ab3a8b0bb781",
  "File": ".env",
  "SymlinkFile": "",
  "Commit": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/5d53f74d1c6c2995e1418c22881e315f04dc0e0d/.env#L9",
  "Entropy": 3.902534,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:53:24Z",
  "Message": "fix(supabase): update project reference and JWT tokens",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d:.env:supabase-key:9"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 9,
  "EndLine": 9,
  "StartColumn": 85,
  "EndColumn": 303,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlsd3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcwNTYzMDY5OCwiZXhwIjoyMDIxMjA2Njk4fQ.0lhQYDxLf5jPFWc7WOjpXfBqFEXe1BtROOD6fEBfLwY",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlsd3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcwNTYzMDY5OCwiZXhwIjoyMDIxMjA2Njk4fQ.0lhQYDxLf5jPFWc7WOjpXfBqFEXe1BtROOD6fEBfLwY",
  "File": ".env",
  "SymlinkFile": "",
  "Commit": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/5d53f74d1c6c2995e1418c22881e315f04dc0e0d/.env#L9",
  "Entropy": 5.4721036,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T19:53:24Z",
  "Message": "fix(supabase): update project reference and JWT tokens",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "5d53f74d1c6c2995e1418c22881e315f04dc0e0d:.env:supabase-key:9"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 82,
  "EndLine": 82,
  "StartColumn": 12,
  "EndColumn": 24,
  "Match": "bearer tokens",
  "Secret": "bearer",
  "File": "DOCUMENTATION.md",
  "SymlinkFile": "",
  "Commit": "9527d833c5871587fac8a39b16a19d4964e635f1",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/9527d833c5871587fac8a39b16a19d4964e635f1/DOCUMENTATION.md?plain=1#L82",
  "Entropy": 1.9182959,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T18:16:23Z",
  "Message": "ci: add ci/security workflows and vercel deploy",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "9527d833c5871587fac8a39b16a19d4964e635f1:DOCUMENTATION.md:generic-bearer:82"
 },
 {
  "RuleID": "mapbox-token",
  "Description": "Mapbox token",
  "StartLine": 12,
  "EndLine": 12,
  "StartColumn": 21,
  "EndColumn": 91,
  "Match": "pk.eyJ1Ijoiamd0b2xlbnRpbm8iLCJhIjoiY21jMmNycWRiMDc0ajJqcHZoaDYyeTJ1NiJ9",
  "Secret": "pk",
  "File": "platform/k8s/secrets/superset-mapbox-secret.yaml",
  "SymlinkFile": "",
  "Commit": "9527d833c5871587fac8a39b16a19d4964e635f1",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/9527d833c5871587fac8a39b16a19d4964e635f1/platform/k8s/secrets/superset-mapbox-secret.yaml#L12",
  "Entropy": 1,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T18:16:23Z",
  "Message": "ci: add ci/security workflows and vercel deploy",
  "Tags": [
   "key",
   "mapbox"
  ],
  "Fingerprint": "9527d833c5871587fac8a39b16a19d4964e635f1:platform/k8s/secrets/superset-mapbox-secret.yaml:mapbox-token:12"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 21,
  "EndColumn": 228,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlkd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MjM2NDczNjQsImV4cCI6MjAzOTIyMzM2NH0.gTJXGSJhgTqsUrwgW2UO5U_YQ4nxQz6XGBKXHG3oRFk",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlkd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MjM2NDczNjQsImV4cCI6MjAzOTIyMzM2NH0.gTJXGSJhgTqsUrwgW2UO5U_YQ4nxQz6XGBKXHG3oRFk",
  "File": "smoke-test-semantic-layer.sh",
  "SymlinkFile": "",
  "Commit": "9527d833c5871587fac8a39b16a19d4964e635f1",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/9527d833c5871587fac8a39b16a19d4964e635f1/smoke-test-semantic-layer.sh#L8",
  "Entropy": 5.5053186,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-27T18:16:23Z",
  "Message": "ci: add ci/security workflows and vercel deploy",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "9527d833c5871587fac8a39b16a19d4964e635f1:smoke-test-semantic-layer.sh:supabase-key:8"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 108,
  "EndLine": 110,
  "StartColumn": 41,
  "EndColumn": 9,
  "Match": "authorization\n\ncommands",
  "Secret": "authorization",
  "File": "pulser/agents/security-engineer.yaml",
  "SymlinkFile": "",
  "Commit": "8c279107c429cd711acdb91104f5a0e77bf9b593",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/8c279107c429cd711acdb91104f5a0e77bf9b593/pulser/agents/security-engineer.yaml#L108-L110",
  "Entropy": 3.085055,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-25T00:52:21Z",
  "Message": "feat(agents): restore missing agents to reach 17 total\n\n- Restored 6 missing Pulser agents: dash, maya, devstral, backend-architect, frontend-architect, performance-engineer\n- Added metadata to MCP agents (DocsWriter, scout-docs-writer)\n- Total agent count now: 17 (11 Pulser, 2 MCP, 1 Config, 1 QA, 1 Task, 1 duplicate)\n- All SuperClaude agents properly registered\n- Quality Engineer v2 with visualization capabilities confirmed\n- Complete inventory in AGENT_INVENTORY_COMPLETE.md",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "8c279107c429cd711acdb91104f5a0e77bf9b593:pulser/agents/security-engineer.yaml:generic-bearer:108"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 11,
  "EndLine": 11,
  "StartColumn": 36,
  "EndColumn": 79,
  "Match": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "Secret": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "File": ".mcp.json",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/.mcp.json#L11",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:.mcp.json:supabase-key:11"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 30,
  "EndLine": 30,
  "StartColumn": 27,
  "EndColumn": 70,
  "Match": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "Secret": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "File": "SKU_CATALOG_AUTO_DEPLOYMENT_COMPLETE.md",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/SKU_CATALOG_AUTO_DEPLOYMENT_COMPLETE.md?plain=1#L30",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:SKU_CATALOG_AUTO_DEPLOYMENT_COMPLETE.md:supabase-key:30"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 100,
  "EndLine": 100,
  "StartColumn": 9,
  "EndColumn": 52,
  "Match": "sbp_bd8639f801700a8137d3007348fcb2a4587e5604",
  "Secret": "sbp_bd8639f801700a8137d3007348fcb2a4587e5604",
  "File": "TASKS_COMPLETION_SUMMARY.md",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/TASKS_COMPLETION_SUMMARY.md?plain=1#L100",
  "Entropy": 3.9905863,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:TASKS_COMPLETION_SUMMARY.md:supabase-key:100"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 75,
  "EndLine": 75,
  "StartColumn": 33,
  "EndColumn": 76,
  "Match": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "Secret": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "File": "platform/scout/MCP_CONFIGURATION.md",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/platform/scout/MCP_CONFIGURATION.md?plain=1#L75",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:platform/scout/MCP_CONFIGURATION.md:supabase-key:75"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 88,
  "EndLine": 88,
  "StartColumn": 34,
  "EndColumn": 77,
  "Match": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "Secret": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "File": "platform/scout/MCP_CONFIGURATION.md",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/platform/scout/MCP_CONFIGURATION.md?plain=1#L88",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:platform/scout/MCP_CONFIGURATION.md:supabase-key:88"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 18,
  "EndLine": 18,
  "StartColumn": 36,
  "EndColumn": 79,
  "Match": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "Secret": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "File": "qa/mcp/mcp.json",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/qa/mcp/mcp.json#L18",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:qa/mcp/mcp.json:supabase-key:18"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 21,
  "EndColumn": 228,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzQ2NzU5NTYsImV4cCI6MjA1MDI1MTk1Nn0.vL80SEOocFh0e0Sz2_cj2HZdlV4jWRpvAcEj_zNcVRM",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzQ2NzU5NTYsImV4cCI6MjA1MDI1MTk1Nn0.vL80SEOocFh0e0Sz2_cj2HZdlV4jWRpvAcEj_zNcVRM",
  "File": "scripts/create_seed_buckets_and_upload.sh",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/scripts/create_seed_buckets_and_upload.sh#L8",
  "Entropy": 5.46117,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:scripts/create_seed_buckets_and_upload.sh:supabase-key:8"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 9,
  "EndLine": 9,
  "StartColumn": 24,
  "EndColumn": 242,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTczNDY3NTk1NiwiZXhwIjoyMDUwMjUxOTU2fQ.6sGcT5Jb8pz8PxY_3MZk9wHZI1JMKVRnWjOaTqjd8X4",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTczNDY3NTk1NiwiZXhwIjoyMDUwMjUxOTU2fQ.6sGcT5Jb8pz8PxY_3MZk9wHZI1JMKVRnWjOaTqjd8X4",
  "File": "scripts/create_seed_buckets_and_upload.sh",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/scripts/create_seed_buckets_and_upload.sh#L9",
  "Entropy": 5.446655,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:scripts/create_seed_buckets_and_upload.sh:supabase-key:9"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 5,
  "EndLine": 5,
  "StartColumn": 32,
  "EndColumn": 75,
  "Match": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "Secret": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "File": "start-claude-mcp.sh",
  "SymlinkFile": "",
  "Commit": "4847cc1d1763832f9f0fc443a4373972016dd3ed",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/4847cc1d1763832f9f0fc443a4373972016dd3ed/start-claude-mcp.sh#L5",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-24T09:30:46Z",
  "Message": "feat: Scout v5.2 Production Hardening Complete\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "4847cc1d1763832f9f0fc443a4373972016dd3ed:start-claude-mcp.sh:supabase-key:5"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 11,
  "EndLine": 11,
  "StartColumn": 36,
  "EndColumn": 79,
  "Match": "sbp_c4c5fa81cc1fde770145ace4e79a33572748b25f",
  "Secret": "sbp_c4c5fa81cc1fde770145ace4e79a33572748b25f",
  "File": ".mcp.json",
  "SymlinkFile": "",
  "Commit": "682a13f6b5deb19cfe5394adfc047774b9e1e018",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/682a13f6b5deb19cfe5394adfc047774b9e1e018/.mcp.json#L11",
  "Entropy": 3.9540036,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:48:18Z",
  "Message": "feat: complete Scout v5.2 backend deployment with agentic analytics\n\n- Add comprehensive agentic analytics infrastructure\n- Deploy Scout v5.2 backend with complete schema alignment\n- Add AI orchestration guides and deployment scripts\n- Implement MCP GitHub integration for automated workflows\n- Add production deployment validation scripts\n- Complete documentation for all new features\n- Add Suqi Chat API integration\n- Deploy Isko worker functions for data processing\n\nThis completes the Scout v5.2 backend deployment with full agentic capabilities",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "682a13f6b5deb19cfe5394adfc047774b9e1e018:.mcp.json:supabase-key:11"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 43,
  "EndLine": 43,
  "StartColumn": 37,
  "EndColumn": 61,
  "Match": "authorization: authHeader",
  "Secret": "authorization",
  "File": "apps/web/app/api/ask-suqi/route.ts",
  "SymlinkFile": "",
  "Commit": "682a13f6b5deb19cfe5394adfc047774b9e1e018",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/682a13f6b5deb19cfe5394adfc047774b9e1e018/apps/web/app/api/ask-suqi/route.ts#L43",
  "Entropy": 3.085055,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:48:18Z",
  "Message": "feat: complete Scout v5.2 backend deployment with agentic analytics\n\n- Add comprehensive agentic analytics infrastructure\n- Deploy Scout v5.2 backend with complete schema alignment\n- Add AI orchestration guides and deployment scripts\n- Implement MCP GitHub integration for automated workflows\n- Add production deployment validation scripts\n- Complete documentation for all new features\n- Add Suqi Chat API integration\n- Deploy Isko worker functions for data processing\n\nThis completes the Scout v5.2 backend deployment with full agentic capabilities",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "682a13f6b5deb19cfe5394adfc047774b9e1e018:apps/web/app/api/ask-suqi/route.ts:generic-bearer:43"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 32,
  "EndLine": 32,
  "StartColumn": 20,
  "EndColumn": 227,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "File": "SUPABASE_SYNC_GUIDE.md",
  "SymlinkFile": "",
  "Commit": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/83378fb4f6a221bb2af2d4fad9231dafad50cdf5/SUPABASE_SYNC_GUIDE.md?plain=1#L32",
  "Entropy": 5.5702257,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5:SUPABASE_SYNC_GUIDE.md:supabase-key:32"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 33,
  "EndLine": 33,
  "StartColumn": 28,
  "EndColumn": 246,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NTIwNjMzNCwiZXhwIjoyMDcwNzgyMzM0fQ.vB9MIfInzX-ch4Kzb-d0_0ndNm-id1MVgQZuDBmtrdw",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NTIwNjMzNCwiZXhwIjoyMDcwNzgyMzM0fQ.vB9MIfInzX-ch4Kzb-d0_0ndNm-id1MVgQZuDBmtrdw",
  "File": "SUPABASE_SYNC_GUIDE.md",
  "SymlinkFile": "",
  "Commit": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/83378fb4f6a221bb2af2d4fad9231dafad50cdf5/SUPABASE_SYNC_GUIDE.md?plain=1#L33",
  "Entropy": 5.3627667,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5:SUPABASE_SYNC_GUIDE.md:supabase-key:33"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 34,
  "EndLine": 34,
  "StartColumn": 24,
  "EndColumn": 67,
  "Match": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "Secret": "sbp_05fcd9a214adbb2721dd54f2f39478e5efcbeffa",
  "File": "SUPABASE_SYNC_GUIDE.md",
  "SymlinkFile": "",
  "Commit": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/83378fb4f6a221bb2af2d4fad9231dafad50cdf5/SUPABASE_SYNC_GUIDE.md?plain=1#L34",
  "Entropy": 3.9474015,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5:SUPABASE_SYNC_GUIDE.md:supabase-key:34"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 4,
  "EndLine": 4,
  "StartColumn": 69,
  "EndColumn": 276,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "File": "services/dashboard/src/config/supabase.ts",
  "SymlinkFile": "",
  "Commit": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/83378fb4f6a221bb2af2d4fad9231dafad50cdf5/services/dashboard/src/config/supabase.ts#L4",
  "Entropy": 5.5702257,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T12:39:20Z",
  "Message": "fix(ci): comprehensive GitHub Actions workflow fixes\n\n- Add SUPABASE_ANON_KEY to GitHub secrets\n- Update storage-buckets.yml and edge-functions.yml with proper env vars\n- Add submodule initialization to all workflows\n- Add environment variable mapping for all Supabase credentials\n- Include sync-supabase.sh step in CI pipeline\n- Enable pull_request triggers for better testing\n- Fix SUPABASE_URL construction from PROJECT_ID\n\nThis resolves all CI failures for PR #32 and dependabot PRs",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "83378fb4f6a221bb2af2d4fad9231dafad50cdf5:services/dashboard/src/config/supabase.ts:supabase-key:4"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 74,
  "EndLine": 74,
  "StartColumn": 34,
  "EndColumn": 77,
  "Match": "sbp_c4c5fa81cc1fde770145ace4e79a33572748b25f",
  "Secret": "sbp_c4c5fa81cc1fde770145ace4e79a33572748b25f",
  "File": "platform/scout/MCP_CONFIGURATION.md",
  "SymlinkFile": "",
  "Commit": "e3f6942be50364aa5754d526bc205adef031e020",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/e3f6942be50364aa5754d526bc205adef031e020/platform/scout/MCP_CONFIGURATION.md?plain=1#L74",
  "Entropy": 3.9540036,
  "Author": "Jake Tolentino",
  "Email": "jake@insightpulse.ai",
  "Date": "2025-08-23T08:35:20Z",
  "Message": "feat: Add scout-databank as submodule with MCP configuration\n\n- Integrated scout-databank-isolated as git submodule at platform/scout/scout-databank/\n- Added comprehensive MCP configuration documentation\n- Configured Playwright and Puppeteer MCP servers for automated testing\n- Documented AI reasoning tracking capabilities\n- Updated platform README with new integrations",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "e3f6942be50364aa5754d526bc205adef031e020:platform/scout/MCP_CONFIGURATION.md:supabase-key:74"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 4,
  "EndLine": 4,
  "StartColumn": 25,
  "EndColumn": 232,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/.env.local",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/.env.local#L4",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/.env.local:supabase-key:4"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 32,
  "EndColumn": 239,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/.env.local",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/.env.local#L8",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/.env.local:supabase-key:8"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 145,
  "EndLine": 145,
  "StartColumn": 13,
  "EndColumn": 32,
  "Match": "authorization header",
  "Secret": "authorization",
  "File": "apps/pi-edge/INTEGRATION.md",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/INTEGRATION.md?plain=1#L145",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/INTEGRATION.md:generic-bearer:145"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 23,
  "EndLine": 23,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md?plain=1#L23",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-key:23"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 51,
  "EndLine": 51,
  "StartColumn": 31,
  "EndColumn": 238,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md?plain=1#L51",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-key:51"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 68,
  "EndLine": 68,
  "StartColumn": 42,
  "EndColumn": 249,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md?plain=1#L68",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-key:68"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 106,
  "EndLine": 106,
  "StartColumn": 59,
  "EndColumn": 266,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md?plain=1#L106",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-key:106"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 134,
  "EndLine": 134,
  "StartColumn": 5,
  "EndColumn": 212,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md?plain=1#L134",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/DEPLOYMENT-FIX-GUIDE.md:supabase-key:134"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 6,
  "EndLine": 6,
  "StartColumn": 24,
  "EndColumn": 231,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/public/runtime-env.js",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/public/runtime-env.js#L6",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/public/runtime-env.js:supabase-key:6"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 10,
  "EndLine": 10,
  "StartColumn": 44,
  "EndColumn": 251,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/public/index.html",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/public/index.html#L10",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/public/index.html:supabase-key:10"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 45,
  "EndLine": 45,
  "StartColumn": 7,
  "EndColumn": 214,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "apps/pi-edge/src/lib/supabase.ts",
  "SymlinkFile": "",
  "Commit": "a530d3a904f2cf5b4403529d98a0441d23b1e71b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/a530d3a904f2cf5b4403529d98a0441d23b1e71b/apps/pi-edge/src/lib/supabase.ts#L45",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-16T17:09:42Z",
  "Message": "ci: harden migrations and fix GitHub Actions failures (#21)\n\n* feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides\n\n* docs: Add comprehensive API documentation and sample responses\n\n- API response examples for all scenarios\n- Dashboard SQL queries for all 4 main views\n- Complete JSON schema reference with annotations\n- Success and error response patterns\n- Real-world query examples for analytics\n\n* feat: Add TBWA gap analysis and complete fix package\n\n- Sample request/response JSON files\n- Compact schema for quick reference\n- Brand backfill script (70+ PH brands)\n- Quality monitoring views and metrics\n- Transcript staging for conversation analytics\n- Updated edge function with transcript capture\n- Comprehensive gap analysis document\n- Deployment checklist and success metrics\n\n* feat: Complete brand resolution system with STT integration\n\n- Brand Universe unifying all sources (STT, catalog, observed)\n- 337+ variant mappings from STT dictionary\n- Server-side resolver with fuzzy matching\n- Automatic brand standardization on insert\n- Token mining from conversation transcripts\n- Comprehensive coverage views and reports\n- Export functionality for edge devices\n- Complete setup and maintenance guide\n\n* feat: Complete quality monitoring and alerting system\n\n- Confusion matrix infrastructure with KPI tracking\n- Automated evaluation schedules (hourly/daily)\n- Quality Sentinel edge function for ClickUp/GitHub integration\n- Per-brand recall/precision/F1 metrics\n- Store-level drift detection\n- Operational alerts with deduplication\n- GitHub Actions workflow for automated checks\n- Comprehensive monitoring guide\n\n* feat: Complete Scout ETL Pipeline with Medallion Architecture\n\n- Bronze: EdgeDevice → scout-edge-ingest → scout_gold_transactions/items\n- Silver: Brand resolution, quality calibration, confusion matrix tracking\n- Gold: Curated views with KPIs, brand universe, operational monitoring\n\nKey features:\n- Real-time transaction ingestion with confidence scoring\n- Brand resolution system with STT dictionary (337+ variants)\n- Quality monitoring with confusion matrix evaluation\n- Automated alerts via ClickUp/GitHub integration\n- SKU scraping infrastructure with queue-based architecture\n- Comprehensive operational dashboards\n\nThis addresses TBWA's critical findings:\n- 99.67% brand data missing → Multi-layered brand resolution\n- No product structure → SKU scraping and catalog integration\n- No quality metrics → Confusion matrix and F1 scoring\n- No demographics → Capture and validation infrastructure\n\nReady for deployment with full monitoring and alerting.\n\n* feat: Production-grade hardening for SKU scraper\n\n- Database optimizations:\n  - Performance indexes on queue and cache tables\n  - Exponential backoff for transient failures (429/503)\n  - Poison queue quarantine after 6 attempts\n  - TTL cleanup for old jobs (30 days)\n  - Double-run prevention trigger\n\n- Master catalog integration:\n  - scout.master_items table for SKU storage\n  - Automatic ingestion from edge function\n  - Deduplication on (source, url, brand, product, pack)\n\n- Operational controls:\n  - Emergency stop with domain throttling\n  - Source quarantine/release functions\n  - Domain-specific rate limiting\n  - Job inspection utilities\n\n- Health monitoring:\n  - Real-time dashboard snapshot\n  - Detailed crawl metrics (queue, cache, items)\n  - Content churn detection\n  - Domain performance tracking\n\n- Automation:\n  - pg_cron schedules for recrawl and cleanup\n  - Stuck job recovery every 6 hours\n  - Worker improvements with proper backoff\n\n- Developer experience:\n  - Comprehensive Makefile targets\n  - Operations guide with playbook\n  - Bruno requests for all operations\n  - Deployment script with health checks\n\nThis completes the production-ready SKU scraping infrastructure,\nready to feed Scout's master catalog with reliable, monitored data.\n\n* feat: Complete multi-source ingestion system with edge computing\n\n- File Ingestion System:\n  - Gmail attachment auto-processing with pattern matching\n  - Google Drive folder monitoring with configurable scanning\n  - Manual upload API with batch support\n  - Priority queue with retry logic\n  - 5 default email triggers configured\n  - Support for JSON, CSV, ZIP, SRT, VTT, Excel formats\n\n- Edge Computing Infrastructure:\n  - Raspberry Pi 5 device fleet management\n  - STT (Speech-to-Text) event processing\n  - OpenCV brand detection integration\n  - Real-time transaction synthesis\n  - 3 devices pre-configured for Manila stores\n  - PH brand catalog (Lucky Me, Nescafe, San Miguel, etc.)\n\n- Integration Features:\n  - Unified analytics across all data sources\n  - Edge-Scout schema bridge\n  - Real-time pipeline monitoring\n  - Store performance comparison\n  - Confidence scoring and alerts\n  - System-wide health dashboard\n\n- API Endpoints:\n  - api.ingest_from_gmail()\n  - api.upload_file()\n  - api.batch_ingest_files()\n  - api.ingest_from_drive()\n  - edge.ingest_edge_event()\n\n- Monitoring \u0026 Operations:\n  - Comprehensive dashboards\n  - Performance metrics\n  - Alert system for low confidence/offline devices\n  - Operations guide with troubleshooting\n\nThis creates a production-ready multi-source data ingestion platform\ncombining email attachments, cloud storage, edge devices, and web scraping\ninto a unified analytics system for Scout.\n\n* feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.\n\n* docs: Add monorepo structure analysis and migration script\n\n* chore: Update edge-suqi-pie submodule reference\n\n* chore: remove submodule and add monorepo configs\n\n* chore: scaffold monorepo structure (apps/, services/, db/, dq/, infra/, CI)\n\n- Imported edge-suqi-pie as subtree at apps/pi-edge with full history\n- Centralized SQL migrations in db/migrations/\n- Organized views and checks in dq/ directory\n- Added pnpm workspace and Turbo configuration\n- Created baseline CI/CD with GitHub Actions\n- Established CODEOWNERS for code review routing\n- Added development Docker Compose configuration\n\n* ci: harden migrations (pgcrypto), seed CI, gate DQ on main, cache pnpm, add health checks",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "a530d3a904f2cf5b4403529d98a0441d23b1e71b:apps/pi-edge/src/lib/supabase.ts:supabase-key:45"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 36,
  "EndLine": 36,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "File": "SHIP-INSTRUCTIONS.md",
  "SymlinkFile": "",
  "Commit": "23b2dde2dfe00332393db412dcd6ca7dc6b4871b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/23b2dde2dfe00332393db412dcd6ca7dc6b4871b/SHIP-INSTRUCTIONS.md?plain=1#L36",
  "Entropy": 5.5702257,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\n🚀 MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\n✅ Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\n✅ Function Deployment: 4/4 edge functions ACTIVE\n✅ Working End-to-End: isko-scraper fully operational\n✅ Error Handling: Structured JSON responses\n✅ Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: ✅ JWT validation \u0026 decode\n- isko-scraper: ✅ Complete scraping pipeline\n- quality-sentinel: 🔧 Auth ready, needs DB schema\n- scout-edge-ingest: 🔧 Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\n🎯 Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "23b2dde2dfe00332393db412dcd6ca7dc6b4871b:SHIP-INSTRUCTIONS.md:supabase-key:36"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 42,
  "EndLine": 42,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUyMDYzMzQsImV4cCI6MjA3MDc4MjMzNH0.adA0EO89jw5uPH4qdL_aox6EbDPvJ28NcXGYW7u33Ok",
  "File": "SHIP-INSTRUCTIONS.md",
  "SymlinkFile": "",
  "Commit": "23b2dde2dfe00332393db412dcd6ca7dc6b4871b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/23b2dde2dfe00332393db412dcd6ca7dc6b4871b/SHIP-INSTRUCTIONS.md?plain=1#L42",
  "Entropy": 5.5702257,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\n🚀 MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\n✅ Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\n✅ Function Deployment: 4/4 edge functions ACTIVE\n✅ Working End-to-End: isko-scraper fully operational\n✅ Error Handling: Structured JSON responses\n✅ Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: ✅ JWT validation \u0026 decode\n- isko-scraper: ✅ Complete scraping pipeline\n- quality-sentinel: 🔧 Auth ready, needs DB schema\n- scout-edge-ingest: 🔧 Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\n🎯 Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "23b2dde2dfe00332393db412dcd6ca7dc6b4871b:SHIP-INSTRUCTIONS.md:supabase-key:42"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 61,
  "EndLine": 61,
  "StartColumn": 19,
  "EndColumn": 38,
  "Match": "authorization header",
  "Secret": "authorization",
  "File": "SHIP-INSTRUCTIONS.md",
  "SymlinkFile": "",
  "Commit": "23b2dde2dfe00332393db412dcd6ca7dc6b4871b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/23b2dde2dfe00332393db412dcd6ca7dc6b4871b/SHIP-INSTRUCTIONS.md?plain=1#L61",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T22:06:13Z",
  "Message": "ship: Scout Scraper v0.1.0 production ready\n\n🚀 MAJOR BREAKTHROUGH - Complete Edge Computing Infrastructure\n\n✅ Authentication Pipeline: 100% RESOLVED (Fixed JWT errors)\n✅ Function Deployment: 4/4 edge functions ACTIVE\n✅ Working End-to-End: isko-scraper fully operational\n✅ Error Handling: Structured JSON responses\n✅ Database Schema: Ready for deployment (ship-database.sql)\n\nFunctions Ready:\n- jwt-echo: ✅ JWT validation \u0026 decode\n- isko-scraper: ✅ Complete scraping pipeline\n- quality-sentinel: 🔧 Auth ready, needs DB schema\n- scout-edge-ingest: 🔧 Auth ready, needs DB tables\n\nShip Status: 85% Complete - Ready for Database Setup\n\n🎯 Generated with Claude Code\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "23b2dde2dfe00332393db412dcd6ca7dc6b4871b:SHIP-INSTRUCTIONS.md:generic-bearer:61"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 4,
  "EndLine": 4,
  "StartColumn": 25,
  "EndColumn": 232,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": ".env.local",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/.env.local#L4",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:.env.local:supabase-key:4"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 32,
  "EndColumn": 239,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": ".env.local",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/.env.local#L8",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:.env.local:supabase-key:8"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 10,
  "EndLine": 10,
  "StartColumn": 44,
  "EndColumn": 251,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "public/index.html",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/public/index.html#L10",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:public/index.html:supabase-key:10"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 6,
  "EndLine": 6,
  "StartColumn": 24,
  "EndColumn": 231,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "public/runtime-env.js",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/public/runtime-env.js#L6",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:public/runtime-env.js:supabase-key:6"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 45,
  "EndLine": 45,
  "StartColumn": 7,
  "EndColumn": 214,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "src/lib/supabase.ts",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/src/lib/supabase.ts#L45",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:src/lib/supabase.ts:supabase-key:45"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 23,
  "EndLine": 23,
  "StartColumn": 30,
  "EndColumn": 237,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/DEPLOYMENT-FIX-GUIDE.md?plain=1#L23",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-key:23"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 51,
  "EndLine": 51,
  "StartColumn": 31,
  "EndColumn": 238,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/DEPLOYMENT-FIX-GUIDE.md?plain=1#L51",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-key:51"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 68,
  "EndLine": 68,
  "StartColumn": 42,
  "EndColumn": 249,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/DEPLOYMENT-FIX-GUIDE.md?plain=1#L68",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-key:68"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 106,
  "EndLine": 106,
  "StartColumn": 59,
  "EndColumn": 266,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/DEPLOYMENT-FIX-GUIDE.md?plain=1#L106",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-key:106"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 134,
  "EndLine": 134,
  "StartColumn": 5,
  "EndColumn": 212,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlvd3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzI5OTA5NjAsImV4cCI6MjA0ODU2Njk2MH0.L1KoNq-I8gI1g-f79PdNfN7kzNajH9gI6MMCpyGNrWE",
  "File": "DEPLOYMENT-FIX-GUIDE.md",
  "SymlinkFile": "",
  "Commit": "75433b2a92652ced7f771c11309e665844d6c653",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/75433b2a92652ced7f771c11309e665844d6c653/DEPLOYMENT-FIX-GUIDE.md?plain=1#L134",
  "Entropy": 5.5826426,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T20:53:53Z",
  "Message": "feat: Scout Analytics Dashboard with Supabase configuration fix\n\n- Robust Supabase client configuration supporting multiple environments:\n  - Vite (VITE_SUPABASE_URL/VITE_SUPABASE_ANON_KEY)\n  - Next.js (NEXT_PUBLIC_SUPABASE_URL/NEXT_PUBLIC_SUPABASE_ANON_KEY)\n  - Runtime window.__ENV__ for static hosting\n  - Meta tags fallback\n  - Hardcoded production values as ultimate fallback\n\n- Complete React dashboard with TypeScript:\n  - Real-time system health monitoring\n  - Edge device status tracking\n  - Pipeline metrics dashboard\n  - File ingestion queue monitoring\n  - Auto-refresh capabilities (5s-60s intervals)\n\n- Data services layer:\n  - fetchDashboardMetrics()\n  - fetchEdgeDeviceStatus()\n  - fetchSystemHealth()\n  - fetchPipelineStatus()\n  - fetchUnifiedAnalytics()\n\n- Custom React hooks:\n  - useScoutDashboard() - Combined data fetching\n  - usePipelineStatus() - Real-time metrics\n  - useEdgeDeviceStatus() - Device monitoring\n\n- Deployment configurations:\n  - Vite build setup with React\n  - Tailwind CSS for styling\n  - Runtime environment injection for Vercel\n  - Environment variable examples\n\nThis fixes the 'supabaseUrl is required' error in the Vercel deployment\nby providing multiple fallback mechanisms for configuration loading.",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "75433b2a92652ced7f771c11309e665844d6c653:DEPLOYMENT-FIX-GUIDE.md:supabase-key:134"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 145,
  "EndLine": 145,
  "StartColumn": 13,
  "EndColumn": 32,
  "Match": "authorization header",
  "Secret": "authorization",
  "File": "INTEGRATION.md",
  "SymlinkFile": "",
  "Commit": "2dde35e565809b2db8bdee89c368b7a6c51a2766",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/2dde35e565809b2db8bdee89c368b7a6c51a2766/INTEGRATION.md?plain=1#L145",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-14T18:12:34Z",
  "Message": "feat: Complete Scout Edge Ingest system with confidence scoring\n\n- Supabase Edge Function for transaction ingestion\n- Gold SQL schema with transactions and items tables\n- Confidence calibration with Brier/ECE metrics\n- Edge device configuration for Raspberry Pi\n- Explainability traces for debugging\n- Quality gates and validation\n- Golden fixture for testing\n- Complete deployment and integration guides",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "2dde35e565809b2db8bdee89c368b7a6c51a2766:INTEGRATION.md:generic-bearer:145"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 19,
  "EndLine": 19,
  "StartColumn": 37,
  "EndColumn": 255,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MjM3NjE4MCwiZXhwIjoyMDY3OTUyMTgwfQ.bHZu_tPiiFVM7fZksLA1lIvflwKENz1t2jowGkx23QI",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MjM3NjE4MCwiZXhwIjoyMDY3OTUyMTgwfQ.bHZu_tPiiFVM7fZksLA1lIvflwKENz1t2jowGkx23QI",
  "File": "manual-deploy-guide.md",
  "SymlinkFile": "",
  "Commit": "7d059e9c3ca08ce6e280e0627d4892f2d5fdb610",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/7d059e9c3ca08ce6e280e0627d4892f2d5fdb610/manual-deploy-guide.md?plain=1#L19",
  "Entropy": 5.505615,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-12T17:34:52Z",
  "Message": "fix: gate production workflows to main branch with secret checks\n\n- Update ci-production.yml to only run on main branch pushes\n- Add git safe.directory configuration for full history checkout\n- Update publish-datasets.yml with secret availability checks\n- Update backup-restore.yml with proper secret gating\n- Switch from npm to pnpm for consistent workspace management\n\nFixes git exit code 128 errors when production workflows run on PRs without secrets.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "7d059e9c3ca08ce6e280e0627d4892f2d5fdb610:manual-deploy-guide.md:supabase-key:19"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 20,
  "EndLine": 20,
  "StartColumn": 15,
  "EndColumn": 205,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyLCJyb2xlIjoiYXV0aGVudGljYXRlZCIsInRlbmFudF9pZCI6InRlc3QtdGVuYW50In0.mock-signature",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyLCJyb2xlIjoiYXV0aGVudGljYXRlZCIsInRlbmFudF9pZCI6InRlc3QtdGVuYW50In0.mock-signature",
  "File": "orchestration/lyra/scripts/learning/test-samples.js",
  "SymlinkFile": "",
  "Commit": "7d059e9c3ca08ce6e280e0627d4892f2d5fdb610",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/7d059e9c3ca08ce6e280e0627d4892f2d5fdb610/orchestration/lyra/scripts/learning/test-samples.js#L20",
  "Entropy": 5.4472847,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-12T17:34:52Z",
  "Message": "fix: gate production workflows to main branch with secret checks\n\n- Update ci-production.yml to only run on main branch pushes\n- Add git safe.directory configuration for full history checkout\n- Update publish-datasets.yml with secret availability checks\n- Update backup-restore.yml with proper secret gating\n- Switch from npm to pnpm for consistent workspace management\n\nFixes git exit code 128 errors when production workflows run on PRs without secrets.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "7d059e9c3ca08ce6e280e0627d4892f2d5fdb610:orchestration/lyra/scripts/learning/test-samples.js:supabase-key:20"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 2,
  "EndLine": 2,
  "StartColumn": 28,
  "EndColumn": 246,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MjM3NjE4MCwiZXhwIjoyMDY3OTUyMTgwfQ.bHZu_tPiiFVM7fZksLA1lIvflwKENz1t2jowGkx23QI",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MjM3NjE4MCwiZXhwIjoyMDY3OTUyMTgwfQ.bHZu_tPiiFVM7fZksLA1lIvflwKENz1t2jowGkx23QI",
  "File": "supabase/.temp.env",
  "SymlinkFile": "",
  "Commit": "7d059e9c3ca08ce6e280e0627d4892f2d5fdb610",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/7d059e9c3ca08ce6e280e0627d4892f2d5fdb610/supabase/.temp.env#L2",
  "Entropy": 5.505615,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-12T17:34:52Z",
  "Message": "fix: gate production workflows to main branch with secret checks\n\n- Update ci-production.yml to only run on main branch pushes\n- Add git safe.directory configuration for full history checkout\n- Update publish-datasets.yml with secret availability checks\n- Update backup-restore.yml with proper secret gating\n- Switch from npm to pnpm for consistent workspace management\n\nFixes git exit code 128 errors when production workflows run on PRs without secrets.\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "7d059e9c3ca08ce6e280e0627d4892f2d5fdb610:supabase/.temp.env:supabase-key:2"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 112,
  "EndLine": 112,
  "StartColumn": 43,
  "EndColumn": 62,
  "Match": "authorization checks",
  "Secret": "authorization",
  "File": "security/policies/policy-engine.ts",
  "SymlinkFile": "",
  "Commit": "7d29db94c707e0c42d9dc1e8848004f6cf03666b",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/7d29db94c707e0c42d9dc1e8848004f6cf03666b/security/policies/policy-engine.ts#L112",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-12T17:23:41Z",
  "Message": "feat: add comprehensive security CI/CD pipeline\n\n- Add security.yml workflow with Trivy, Semgrep, TruffleHog scanners\n- Add security-nightly.yml for full git history scanning\n- Implement policy enforcement with configurable thresholds\n- Add security allowlists and custom Semgrep rules\n- Include test script for local security pipeline validation\n\n🤖 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "7d29db94c707e0c42d9dc1e8848004f6cf03666b:security/policies/policy-engine.ts:generic-bearer:112"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 29,
  "EndLine": 29,
  "StartColumn": 115,
  "EndColumn": 373,
  "Match": "eyJraWQiOiJzdG9yYWdlLXVybC1zaWduaW5nLWtleV9lZDdiZGI2YS05YzY1LTQxOTktYTJkNS01NzFmMWQ4NWIyZjciLCJhbGciOiJIUzI1NiJ9.eyJ1cmwiOiJzY291dC1pbmdlc3QvZWRnZS1pbmJveC9qc29uLnppcCIsImlhdCI6MTc1NDkwNDA5MiwiZXhwIjoxNzU1NTA4ODkyfQ.HZE-BRypOov2xldWCkIynMDVTQlM8zhb4Qf1s73Ke1o",
  "Secret": "eyJraWQiOiJzdG9yYWdlLXVybC1zaWduaW5nLWtleV9lZDdiZGI2YS05YzY1LTQxOTktYTJkNS01NzFmMWQ4NWIyZjciLCJhbGciOiJIUzI1NiJ9.eyJ1cmwiOiJzY291dC1pbmdlc3QvZWRnZS1pbmJveC9qc29uLnppcCIsImlhdCI6MTc1NDkwNDA5MiwiZXhwIjoxNzU1NTA4ODkyfQ.HZE-BRypOov2xldWCkIynMDVTQlM8zhb4Qf1s73Ke1o",
  "File": "scripts/process-edge-inbox.js",
  "SymlinkFile": "",
  "Commit": "2fa68cf0ffdf720ce7281d7af5ff3ba5161fec65",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/2fa68cf0ffdf720ce7281d7af5ff3ba5161fec65/scripts/process-edge-inbox.js#L29",
  "Entropy": 5.6437235,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-11T17:27:00Z",
  "Message": "feat: add ETL processor and fix PhilippinesMap component\n\n- Added process-edge-inbox.js script to handle edge-inbox ZIP files\n- Fixed PhilippinesMap.tsx runtime error with proper error handling\n- Script processes json.zip and scoutpi-0003.zip from storage bucket\n- Supports Bronze → Silver → Gold → Platinum pipeline processing",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "2fa68cf0ffdf720ce7281d7af5ff3ba5161fec65:scripts/process-edge-inbox.js:supabase-key:29"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 33,
  "EndLine": 33,
  "StartColumn": 123,
  "EndColumn": 391,
  "Match": "eyJraWQiOiJzdG9yYWdlLXVybC1zaWduaW5nLWtleV9lZDdiZGI2YS05YzY1LTQxOTktYTJkNS01NzFmMWQ4NWIyZjciLCJhbGciOiJIUzI1NiJ9.eyJ1cmwiOiJzY291dC1pbmdlc3QvZWRnZS1pbmJveC9zY291dHBpLTAwMDMuemlwIiwiaWF0IjoxNzU0OTA0MTA1LCJleHAiOjE3NTU1MDg5MDV9.LyPjPuRXlHv0wj7FalB1kXGAOmH0UvJm_oAwVD9els4",
  "Secret": "eyJraWQiOiJzdG9yYWdlLXVybC1zaWduaW5nLWtleV9lZDdiZGI2YS05YzY1LTQxOTktYTJkNS01NzFmMWQ4NWIyZjciLCJhbGciOiJIUzI1NiJ9.eyJ1cmwiOiJzY291dC1pbmdlc3QvZWRnZS1pbmJveC9zY291dHBpLTAwMDMuemlwIiwiaWF0IjoxNzU0OTA0MTA1LCJleHAiOjE3NTU1MDg5MDV9.LyPjPuRXlHv0wj7FalB1kXGAOmH0UvJm_oAwVD9els4",
  "File": "scripts/process-edge-inbox.js",
  "SymlinkFile": "",
  "Commit": "2fa68cf0ffdf720ce7281d7af5ff3ba5161fec65",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/2fa68cf0ffdf720ce7281d7af5ff3ba5161fec65/scripts/process-edge-inbox.js#L33",
  "Entropy": 5.619755,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-11T17:27:00Z",
  "Message": "feat: add ETL processor and fix PhilippinesMap component\n\n- Added process-edge-inbox.js script to handle edge-inbox ZIP files\n- Fixed PhilippinesMap.tsx runtime error with proper error handling\n- Script processes json.zip and scoutpi-0003.zip from storage bucket\n- Supports Bronze → Silver → Gold → Platinum pipeline processing",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "2fa68cf0ffdf720ce7281d7af5ff3ba5161fec65:scripts/process-edge-inbox.js:supabase-key:33"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 452,
  "EndLine": 452,
  "StartColumn": 30,
  "EndColumn": 49,
  "Match": "authorization header",
  "Secret": "authorization",
  "File": "platform/scout/functions/dataset-subscriptions/index.ts",
  "SymlinkFile": "",
  "Commit": "96a6cf2287b8a43fea987302efc67a4869aea9b8",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/96a6cf2287b8a43fea987302efc67a4869aea9b8/platform/scout/functions/dataset-subscriptions/index.ts#L452",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-11T03:31:13Z",
  "Message": "✅ Complete 100% project implementation - All 61 tasks done\n\n- Dataset usage analytics dashboard with comprehensive tracking\n- Dataset versioning and rollback mechanism with semantic versioning\n- Cross-region replication system for global availability\n- Dataset subscription notifications with multi-channel support\n- Complete test suites and deployment automation\n- All Edge Functions and database schemas implemented\n- Production-ready with monitoring and security features\n\nTotal completion: 61/61 tasks (100%)\n- High Priority: 17/17 ✅\n- Medium Priority: 25/25 ✅\n- Low Priority: 19/19 ✅",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "96a6cf2287b8a43fea987302efc67a4869aea9b8:platform/scout/functions/dataset-subscriptions/index.ts:generic-bearer:452"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 20,
  "EndLine": 20,
  "StartColumn": 54,
  "EndColumn": 73,
  "Match": "authorization header",
  "Secret": "authorization",
  "File": "scripts/validate-token-edge-function.ts",
  "SymlinkFile": "",
  "Commit": "96a6cf2287b8a43fea987302efc67a4869aea9b8",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/96a6cf2287b8a43fea987302efc67a4869aea9b8/scripts/validate-token-edge-function.ts#L20",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-11T03:31:13Z",
  "Message": "✅ Complete 100% project implementation - All 61 tasks done\n\n- Dataset usage analytics dashboard with comprehensive tracking\n- Dataset versioning and rollback mechanism with semantic versioning\n- Cross-region replication system for global availability\n- Dataset subscription notifications with multi-channel support\n- Complete test suites and deployment automation\n- All Edge Functions and database schemas implemented\n- Production-ready with monitoring and security features\n\nTotal completion: 61/61 tasks (100%)\n- High Priority: 17/17 ✅\n- Medium Priority: 25/25 ✅\n- Low Priority: 19/19 ✅",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "96a6cf2287b8a43fea987302efc67a4869aea9b8:scripts/validate-token-edge-function.ts:generic-bearer:20"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 87,
  "EndLine": 87,
  "StartColumn": 19,
  "EndColumn": 41,
  "Match": "authorization.k8s.io/v1",
  "Secret": "authorization",
  "File": "platform/security/secret-rotation.yaml",
  "SymlinkFile": "",
  "Commit": "2a1ea4e53dfb071b925a41388a747ea451cc3f31",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/2a1ea4e53dfb071b925a41388a747ea451cc3f31/platform/security/secret-rotation.yaml#L87",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T10:10:28Z",
  "Message": "fix: implement comprehensive CI/CD fixes and improvements\n\nBased on project review feedback:\n\nCI/CD Fixes:\n- Fix dbt profile with DuckDB for CI (no cluster dependency)\n- Initialize Great Expectations with proper configuration\n- Update profiles.yml with ci/dev/prod targets\n\nPerformance Optimizations:\n- Add composite indexes for common query patterns\n  - idx_silver_region_category_date\n  - idx_silver_barangay_category_date\n  - idx_silver_sku_date_store\n\nCode Quality Improvements:\n- Add error boundary to computePesoValue function\n- Add comprehensive unit tests for Edge Functions\n- Implement proper error handling with fallbacks\n\nSecurity Enhancements:\n- Add automated secret rotation CronJob\n- Weekly rotation for database passwords, JWT secrets, and API keys\n- Proper RBAC for secret-rotator service account\n\nThis brings the project to production-ready status with 85/100 score",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "2a1ea4e53dfb071b925a41388a747ea451cc3f31:platform/security/secret-rotation.yaml:generic-bearer:87"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 101,
  "EndLine": 101,
  "StartColumn": 19,
  "EndColumn": 41,
  "Match": "authorization.k8s.io/v1",
  "Secret": "authorization",
  "File": "platform/security/secret-rotation.yaml",
  "SymlinkFile": "",
  "Commit": "2a1ea4e53dfb071b925a41388a747ea451cc3f31",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/2a1ea4e53dfb071b925a41388a747ea451cc3f31/platform/security/secret-rotation.yaml#L101",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T10:10:28Z",
  "Message": "fix: implement comprehensive CI/CD fixes and improvements\n\nBased on project review feedback:\n\nCI/CD Fixes:\n- Fix dbt profile with DuckDB for CI (no cluster dependency)\n- Initialize Great Expectations with proper configuration\n- Update profiles.yml with ci/dev/prod targets\n\nPerformance Optimizations:\n- Add composite indexes for common query patterns\n  - idx_silver_region_category_date\n  - idx_silver_barangay_category_date\n  - idx_silver_sku_date_store\n\nCode Quality Improvements:\n- Add error boundary to computePesoValue function\n- Add comprehensive unit tests for Edge Functions\n- Implement proper error handling with fallbacks\n\nSecurity Enhancements:\n- Add automated secret rotation CronJob\n- Weekly rotation for database passwords, JWT secrets, and API keys\n- Proper RBAC for secret-rotator service account\n\nThis brings the project to production-ready status with 85/100 score",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "2a1ea4e53dfb071b925a41388a747ea451cc3f31:platform/security/secret-rotation.yaml:generic-bearer:101"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 107,
  "EndLine": 107,
  "StartColumn": 19,
  "EndColumn": 38,
  "Match": "authorization.k8s.io",
  "Secret": "authorization",
  "File": "platform/security/secret-rotation.yaml",
  "SymlinkFile": "",
  "Commit": "2a1ea4e53dfb071b925a41388a747ea451cc3f31",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/2a1ea4e53dfb071b925a41388a747ea451cc3f31/platform/security/secret-rotation.yaml#L107",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T10:10:28Z",
  "Message": "fix: implement comprehensive CI/CD fixes and improvements\n\nBased on project review feedback:\n\nCI/CD Fixes:\n- Fix dbt profile with DuckDB for CI (no cluster dependency)\n- Initialize Great Expectations with proper configuration\n- Update profiles.yml with ci/dev/prod targets\n\nPerformance Optimizations:\n- Add composite indexes for common query patterns\n  - idx_silver_region_category_date\n  - idx_silver_barangay_category_date\n  - idx_silver_sku_date_store\n\nCode Quality Improvements:\n- Add error boundary to computePesoValue function\n- Add comprehensive unit tests for Edge Functions\n- Implement proper error handling with fallbacks\n\nSecurity Enhancements:\n- Add automated secret rotation CronJob\n- Weekly rotation for database passwords, JWT secrets, and API keys\n- Proper RBAC for secret-rotator service account\n\nThis brings the project to production-ready status with 85/100 score",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "2a1ea4e53dfb071b925a41388a747ea451cc3f31:platform/security/secret-rotation.yaml:generic-bearer:107"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 116,
  "EndLine": 116,
  "StartColumn": 19,
  "EndColumn": 38,
  "Match": "authorization.k8s.io",
  "Secret": "authorization",
  "File": "platform/lakehouse/dbt/dbt-cronjob.yaml",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/00e83a6029b7266df02e603c2dd25caaa514de4c/platform/lakehouse/dbt/dbt-cronjob.yaml#L116",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronze→Silver→Gold→Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset ⇄ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\n🌍 Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\n🔐 Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\n📊 Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\n🚀 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/lakehouse/dbt/dbt-cronjob.yaml:generic-bearer:116"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 5,
  "EndLine": 5,
  "StartColumn": 30,
  "EndColumn": 248,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MjM3NjE4MCwiZXhwIjoyMDY3OTUyMTgwfQ.bHZu_tPiiFVM7fZksLA1lIvflwKENz1t2jowGkx23QI",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MjM3NjE4MCwiZXhwIjoyMDY3OTUyMTgwfQ.bHZu_tPiiFVM7fZksLA1lIvflwKENz1t2jowGkx23QI",
  "File": "platform/scout/bruno/environments.json",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/00e83a6029b7266df02e603c2dd25caaa514de4c/platform/scout/bruno/environments.json#L5",
  "Entropy": 5.505615,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronze→Silver→Gold→Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset ⇄ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\n🌍 Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\n🔐 Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\n📊 Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\n🚀 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments.json:supabase-key:5"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 6,
  "EndLine": 6,
  "StartColumn": 26,
  "EndColumn": 233,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTIzNzYxODAsImV4cCI6MjA2Nzk1MjE4MH0.b794GEIWE4ZdMAm9xQYAJ0Gx-XEn1fhJBTIIeTro_1g",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTIzNzYxODAsImV4cCI6MjA2Nzk1MjE4MH0.b794GEIWE4ZdMAm9xQYAJ0Gx-XEn1fhJBTIIeTro_1g",
  "File": "platform/scout/bruno/environments.json",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/00e83a6029b7266df02e603c2dd25caaa514de4c/platform/scout/bruno/environments.json#L6",
  "Entropy": 5.4883657,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronze→Silver→Gold→Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset ⇄ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\n🌍 Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\n🔐 Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\n📊 Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\n🚀 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments.json:supabase-key:6"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 19,
  "EndLine": 19,
  "StartColumn": 26,
  "EndColumn": 233,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTIzNzYxODAsImV4cCI6MjA2Nzk1MjE4MH0.b794GEIWE4ZdMAm9xQYAJ0Gx-XEn1fhJBTIIeTro_1g",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenl4d3B5cHRmcmV0cnljIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTIzNzYxODAsImV4cCI6MjA2Nzk1MjE4MH0.b794GEIWE4ZdMAm9xQYAJ0Gx-XEn1fhJBTIIeTro_1g",
  "File": "platform/scout/bruno/environments.json",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/00e83a6029b7266df02e603c2dd25caaa514de4c/platform/scout/bruno/environments.json#L19",
  "Entropy": 5.4883657,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronze→Silver→Gold→Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset ⇄ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\n🌍 Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\n🔐 Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\n📊 Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\n🚀 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments.json:supabase-key:19"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 7,
  "EndLine": 7,
  "StartColumn": 23,
  "EndColumn": 197,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlwdHlwdGZyZXRyeWMiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY5NzQ4NDg2NCwiZXhwIjoyMDEzMDYwODY0fQ.example_key",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlwdHlwdGZyZXRyeWMiLCJyb2xlIjoiYW5vbiIsImlhdCI6MTY5NzQ4NDg2NCwiZXhwIjoyMDEzMDYwODY0fQ.example_key",
  "File": "platform/scout/bruno/environments/production.bru",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/00e83a6029b7266df02e603c2dd25caaa514de4c/platform/scout/bruno/environments/production.bru#L7",
  "Entropy": 5.385202,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronze→Silver→Gold→Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset ⇄ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\n🌍 Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\n🔐 Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\n📊 Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\n🚀 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments/production.bru:supabase-key:7"
 },
 {
  "RuleID": "supabase-key",
  "Description": "Supabase key (anon/service/JWT)",
  "StartLine": 8,
  "EndLine": 8,
  "StartColumn": 26,
  "EndColumn": 210,
  "Match": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlwdHlwdGZyZXRyeWMiLCJyb2xlIjoic2VydmljZV9yb2xlIiwiaWF0IjoxNjk3NDg0ODY0LCJleHAiOjIwMTMwNjA4NjR9.service_key",
  "Secret": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImN4emxsenlwdHlwdGZyZXRyeWMiLCJyb2xlIjoic2VydmljZV9yb2xlIiwiaWF0IjoxNjk3NDg0ODY0LCJleHAiOjIwMTMwNjA4NjR9.service_key",
  "File": "platform/scout/bruno/environments/production.bru",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/00e83a6029b7266df02e603c2dd25caaa514de4c/platform/scout/bruno/environments/production.bru#L8",
  "Entropy": 5.3906116,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronze→Silver→Gold→Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset ⇄ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\n🌍 Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\n🔐 Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\n📊 Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\n🚀 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "supabase",
   "jwt"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:platform/scout/bruno/environments/production.bru:supabase-key:8"
 },
 {
  "RuleID": "mapbox-token",
  "Description": "Mapbox token",
  "StartLine": 17,
  "EndLine": 17,
  "StartColumn": 36,
  "EndColumn": 106,
  "Match": "pk.eyJ1Ijoiamd0b2xlbnRpbm8iLCJhIjoiY21jMmNycWRiMDc0ajJqcHZoaDYyeTJ1NiJ9",
  "Secret": "pk",
  "File": "scripts/verify_choropleth_complete.sh",
  "SymlinkFile": "",
  "Commit": "00e83a6029b7266df02e603c2dd25caaa514de4c",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/00e83a6029b7266df02e603c2dd25caaa514de4c/scripts/verify_choropleth_complete.sh#L17",
  "Entropy": 1,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-10T03:00:59Z",
  "Message": "feat: implement hardened lakehouse with geographic visualization\n\n- Add complete Scout Analytics platform (Bronze→Silver→Gold→Platinum)\n- Implement choropleth visualization with PostGIS and Mapbox integration\n- Add cloud-wire API-first Superset ⇄ Supabase integration\n- Include comprehensive security hardening (Gatekeeper, RLS, CSRF)\n- Add performance optimization (GIST indexes, simplified geometries)\n- Include full test coverage (Bruno API tests, performance benchmarks)\n- Add production deployment automation and monitoring\n\n🌍 Geographic features:\n- Philippine administrative boundaries (ADM1/2/3)\n- Interactive choropleth maps with Deck.gl\n- Performance gates: \u003c1.5s query, \u003c2.5s render, \u003e99% join coverage\n\n🔐 Security features:\n- Row-level security policies\n- Gatekeeper admission controllers\n- Secret management via Kubernetes\n- CSRF protection and CSP headers\n\n📊 Performance features:\n- Idempotent ingestion with event hashing\n- Materialized view refresh with advisory locks\n- GIST spatial indexes for sub-second queries\n- Comprehensive benchmarking and monitoring\n\n🚀 Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude \u003cnoreply@anthropic.com\u003e",
  "Tags": [
   "key",
   "mapbox"
  ],
  "Fingerprint": "00e83a6029b7266df02e603c2dd25caaa514de4c:scripts/verify_choropleth_complete.sh:mapbox-token:17"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 25,
  "EndLine": 25,
  "StartColumn": 19,
  "EndColumn": 41,
  "Match": "authorization.k8s.io/v1",
  "Secret": "authorization",
  "File": "platform/lakehouse/dbt/dbt-cronjob.yaml",
  "SymlinkFile": "",
  "Commit": "343bdab538b48512a1069e45adb68e6a13d5d1ce",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/343bdab538b48512a1069e45adb68e6a13d5d1ce/platform/lakehouse/dbt/dbt-cronjob.yaml#L25",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-09T12:37:30Z",
  "Message": "Hardened lakehouse: MinIO+Nessie+Trino+dbt+NetPol+CI",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "343bdab538b48512a1069e45adb68e6a13d5d1ce:platform/lakehouse/dbt/dbt-cronjob.yaml:generic-bearer:25"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 32,
  "EndLine": 32,
  "StartColumn": 19,
  "EndColumn": 41,
  "Match": "authorization.k8s.io/v1",
  "Secret": "authorization",
  "File": "platform/lakehouse/dbt/dbt-cronjob.yaml",
  "SymlinkFile": "",
  "Commit": "343bdab538b48512a1069e45adb68e6a13d5d1ce",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/343bdab538b48512a1069e45adb68e6a13d5d1ce/platform/lakehouse/dbt/dbt-cronjob.yaml#L32",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-09T12:37:30Z",
  "Message": "Hardened lakehouse: MinIO+Nessie+Trino+dbt+NetPol+CI",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "343bdab538b48512a1069e45adb68e6a13d5d1ce:platform/lakehouse/dbt/dbt-cronjob.yaml:generic-bearer:32"
 },
 {
  "RuleID": "generic-bearer",
  "Description": "Generic bearer token",
  "StartLine": 36,
  "EndLine": 36,
  "StartColumn": 58,
  "EndColumn": 77,
  "Match": "authorization.k8s.io",
  "Secret": "authorization",
  "File": "platform/lakehouse/dbt/dbt-cronjob.yaml",
  "SymlinkFile": "",
  "Commit": "343bdab538b48512a1069e45adb68e6a13d5d1ce",
  "Link": "https://github.com/jgtolentino/ai-aas-hardened-lakehouse/blob/343bdab538b48512a1069e45adb68e6a13d5d1ce/platform/lakehouse/dbt/dbt-cronjob.yaml#L36",
  "Entropy": 3.085055,
  "Author": "jgtolentino",
  "Email": "jgtolentino_rn@yahoo.com",
  "Date": "2025-08-09T12:37:30Z",
  "Message": "Hardened lakehouse: MinIO+Nessie+Trino+dbt+NetPol+CI",
  "Tags": [
   "key",
   "generic"
  ],
  "Fingerprint": "343bdab538b48512a1069e45adb68e6a13d5d1ce:platform/lakehouse/dbt/dbt-cronjob.yaml:generic-bearer:36"
 }
]
